{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graphs in Cypher\n",
    "\n",
    "This notebook gives an introduction to the Cypher query language used in the [Neo4j graph database](https://neo4j.com/) based on previous knowledge of the SQL language and the [PostgreSQL](https://www.postgresql.org/) database. See our previous notebook [`Graphs in SQL'](https://github.com/BigDataAnalyticsGroup/bigdataengineering/blob/master/Graphs%20in%20SQL.ipynb) on how to query graphs in SQL.\n",
    "\n",
    "\n",
    "We use the same examples and queries as the previous notebook on SQL, however this time using just Cypher. To visualize the graphs, we use the [`vis.js`](https://visjs.org/) library as presented in the [neo4j-jupyter notebooks by Nicole White](https://github.com/nicolewhite/neo4j-jupyter).\n",
    "\n",
    "Copyright Christian SchÃ¶n & Jens Dittrich, [Big Data Analytics Group](https://bigdata.uni-saarland.de/), [CC-BY-SA](https://creativecommons.org/licenses/by-sa/4.0/legalcode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup - Neo4j\n",
    "\n",
    "The Neo4j database which we will now set up will contain the same data as the PostgreSQL database used in first part of this notebook series, however with a slightly different layout. Instead of storing everything as tables, Neo4j distinguishes between nodes and edges."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neo4j\n",
    "\n",
    "[Neo4j](https://neo4j.com/) is a graph database that is available for free for personal use. You can either [download Neo4j](https://neo4j.com/download-center/#community) and execute it locally or you can use a [blank online sandbox](https://neo4j.com/sandbox-v2/). Be careful: If you execute Neo4j locally, you have to change the password at least once and adapt the settings below before executing this notebook. In both cases (offline and online), you will need the following information to establish a connection to the database:\n",
    "* ip-address and bolt port of the computer the database is running on\n",
    "* username and password for authentication\n",
    "\n",
    "If you use an online sandbox, the necessary information is displayed in the details tab after startup. A graph database does not store tables as classic RDBMS, but nodes and edges. The query language used is called [Cypher](https://neo4j.com/developer/cypher-query-language/) and differs from the SQL language of e.g. PostgreSQL.\n",
    "\n",
    "We will first setup the same example as in PostgreSQL, i.e. using nodes labelled with `PERSON` and edges labelled with `KNOWS`, `MEETS`, or `WRITES`. In a second step, we then also implement the precedence graph example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify paths to CSV files for social network\n",
    "contacts_persons_csv = \"./data/cypher/contacts_persons.csv\"\n",
    "contacts_knows_csv = \"./data/cypher/contacts_knows.csv\"\n",
    "contacts_meets_csv = \"./data/cypher/contacts_meets.csv\"\n",
    "contacts_writes_csv = \"./data/cypher/contacts_writes.csv\"\n",
    "\n",
    "# Specify paths to CSV files for precedence graph\n",
    "transactions_nodes_csv = \"./data/cypher/transactions_nodes.csv\"\n",
    "transactions_precedence_csv = \"./data/cypher/transactions_precedence.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import functions used to draw results in later sections\n",
    "from vis.vis import drawSubgraph, print_set_postgres, print_set_neo4j\n",
    "# Import the Neo4j driver and the csv package\n",
    "from py2neo import Graph\n",
    "import csv\n",
    "\n",
    "# Setup connection to the Neo4j graph\n",
    "# Schema of uri: \"bolt://ip:port\"\n",
    "# Schema of auth: (\"username\", \"password\")\n",
    "graph = Graph(profile=\"bolt://127.0.0.1:7687\", auth=(\"neo4j\", \"h6u4%kr\"))\n",
    "\n",
    "# Reset graph\n",
    "graph.run(\"MATCH (n) DETACH DELETE n;\")\n",
    "\n",
    "# Specify which property to display as label in a node\n",
    "options = {\n",
    "    \"PERSON\": \"name\",\n",
    "    \"TRANSACTION\": \"name\"\n",
    "}\n",
    "\n",
    "# Enable physics effect\n",
    "physics = True\n",
    "# Set node shape: circle with labels inside or dot with labels below\n",
    "node_shape = 'circle'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Social network graph\n",
    "\n",
    "# Create constraints, i.e. a primary key constraint:\n",
    "graph.run(\"CREATE CONSTRAINT IF NOT EXISTS ON (n:Person) ASSERT n.node_id IS UNIQUE;\")\n",
    "\n",
    "# Create nodes labelled with 'PERSON'\n",
    "with open(contacts_persons_csv, newline='') as csvfile:\n",
    "    csvreader = csv.DictReader(csvfile)\n",
    "    for row in csvreader:\n",
    "        graph.run(\"MERGE (n:PERSON {{node_id: {}, name:'{}'}});\".format(int(row['node_id']), str(row['name'])))\n",
    "        \n",
    "for csv_name, relationship in [(contacts_knows_csv, 'KNOWS'), (contacts_meets_csv, 'MEETS'), (contacts_writes_csv, 'WRITES')]:        \n",
    "#  Create relationships labelled  'knows', 'meets' and 'writes':\n",
    "    with open(csv_name, newline='') as csvfile:\n",
    "        csvreader = csv.DictReader(csvfile)\n",
    "        for row in csvreader:\n",
    "            graph.run((\"MATCH (p1:PERSON {{node_id: {}}}) MATCH (p2:PERSON {{node_id: {}}}) MERGE (p1)-[r:\"+relationship+\"]->(p2);\").format(int(row['start_id']), int(row['end_id'])))\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Precedence graph\n",
    "\n",
    "# Create constraints\n",
    "graph.run(\"CREATE CONSTRAINT IF NOT EXISTS ON (n:TRANSACTION) ASSERT n.node_id IS UNIQUE;\")\n",
    "\n",
    "# Create nodes labelled with 'TRANSACTION'\n",
    "with open(transactions_nodes_csv, newline='') as csvfile:\n",
    "    csvreader = csv.DictReader(csvfile)\n",
    "    for row in csvreader:\n",
    "        graph.run(\"MERGE (n:TRANSACTION {{node_id: {}, name:'{}'}});\".format(int(row['node_id']), str(row['name'])))\n",
    "\n",
    "# Create relationships labelled with 'KNOWS'\n",
    "with open(transactions_precedence_csv, newline='') as csvfile:\n",
    "    csvreader = csv.DictReader(csvfile)\n",
    "    for row in csvreader:\n",
    "        graph.run(\"MATCH (p1:TRANSACTION {{node_id: {}}}) MATCH (p2:TRANSACTION {{node_id: {}}}) MERGE (p1)-[r:PRECEDENCE]->(p2);\".format(int(row['start_id']), int(row['end_id'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Social Network Graph - Neo4j\n",
    "\n",
    "Again, our first example is the social network graph, consisting of four persons in total which might know, meet, or write with another person in the network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple Queries - Neo4j\n",
    "\n",
    "To check if the Neo4j database is setup correctly, we use the same example as for the PostgreSQL database, i.e. querying the nodes in the database. The result should consist of four persons with IDs 0 to 4 and names 'A' to 'D'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Result] : {[ node_id, name ]}\n",
      "{\n",
      "\t(0, A),\n",
      "\t(1, B),\n",
      "\t(3, C),\n",
      "\t(2, D)\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Neo4j\n",
    "# MATCH (n:PERSON) corresponds to FROM person AS n in SQL\n",
    "# RETURN corresponds to SELECT in SQL\n",
    "cur = graph.run(\"\"\"\n",
    "MATCH (n:PERSON)\n",
    "RETURN n.node_id AS node_id, n.name AS name;\n",
    "\"\"\")\n",
    "print_set_neo4j(cur)\n",
    "#cur.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which person knows which other person using directed edges:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Result] : {[ r ]}\n",
      "{\n",
      "\t((A)-[:KNOWS {}]->(B)),\n",
      "\t((A)-[:KNOWS {}]->(C))\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "cur = graph.run(\"\"\"\n",
    "MATCH ()-[r:KNOWS]->()\n",
    "RETURN r;\n",
    "\"\"\")\n",
    "print_set_neo4j(cur)\n",
    "#cur.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which person knows which other person, this time using undirected edges:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Result] : {[ r ]}\n",
      "{\n",
      "\t((A)-[:KNOWS {}]->(C)),\n",
      "\t((A)-[:KNOWS {}]->(B)),\n",
      "\t((A)-[:KNOWS {}]->(B)),\n",
      "\t((A)-[:KNOWS {}]->(C))\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "cur = graph.run(\"\"\"\n",
    "MATCH ()-[r:KNOWS]-() RETURN r;\n",
    "\"\"\")\n",
    "print_set_neo4j(cur)\n",
    "#cur.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can again also output only the names of the two persons:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Result] : {[ n.name, n2.name ]}\n",
      "{\n",
      "\t(A, B),\n",
      "\t(A, C)\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Neo4j\n",
    "# () - [...] -> () is Cypher's ASCII query syntax:\n",
    "# Find all persons that know another person and return the names of both persons:\n",
    "cur = graph.run(\"\"\"\n",
    "MATCH (n:PERSON) - [r:KNOWS] -> (n2:PERSON)\n",
    "RETURN n.name, n2.name;\n",
    "\"\"\")\n",
    "print_set_neo4j(cur)\n",
    "#cur.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Precedence Graph (Neo4j)\n",
    "\n",
    "We now move on the basic transaction graph example already presented in the previous notebook of this series. Our task is again the search for cycles.\n",
    "As a reminder, we visualize the graph first, this time by directly querying the Neo4j database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"300\"\n",
       "            src=\"pics/vis_generated/basic_example.html\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7fee64bc9750>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# edges: (t1:TRANSACTION) --> (t2:TRANSACTION) describes a path,\n",
    "# i.e. a node of type transaction leading via an edge to some other node of type transaction\n",
    "# WHERE correpsonds to WHERE in SQL\n",
    "# here: only consider nodes with an id <= 3.\n",
    "data_neo4j = graph.run(\"\"\"\n",
    "MATCH edges = (a:TRANSACTION) --> (b:TRANSACTION)\n",
    "WHERE a.node_id <= 3 AND b.node_id <= 3\n",
    "RETURN edges;\n",
    "\"\"\").to_subgraph()\n",
    "drawSubgraph(data_neo4j, options, height=\"300\", filename=\"basic_example.html\", physics=physics, node_shape=node_shape, edge_width=3.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cypher (Naive Way)\n",
    "\n",
    "Cypher, the query language used by Neo4j, can also detect cycles using its built-in features. However, the query remains way shorter and more readable compared to SQL. We match all transactions `a` which are related through up to 3 edges with themselves and assign the result to `cyclePath`. We then extract all nodes from `cyclePath` and store them in the variable `path`. We finally return the `node_id` of the first node on the path, the length of the path and a list containing the `node_id` of each node in the path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Result] : {[ startID, length, path ]}\n",
      "{\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# WITH corresponds to WITH in SQL:\n",
    "# here: NODES(cyclePath) returns an ordered (index-based) list of nodes that are part of the cyclePath\n",
    "# [] is a list comprehension similar to Python, however in reverse order\n",
    "#  [n IN path | n.node_id] is a list of the node_ids contained in path\n",
    "cur = graph.run(\"\"\"\n",
    "MATCH cyclePath = (a:TRANSACTION) - [*..3] -> (a)\n",
    "WITH NODES(cyclePath) as path\n",
    "RETURN path[0].node_id AS startID, SIZE(path) AS length, [n IN path | n.node_id] AS path;\n",
    "\"\"\")\n",
    "print_set_neo4j(cur)\n",
    "#cur.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced Precedence Graph\n",
    "\n",
    "In the following, we will move on to the extended example consisting of nine transactions containing multiple possible cycles as already presented above. We again visualize it using Neo4j."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"500\"\n",
       "            src=\"pics/vis_generated/advanced_example.html\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7fee64870e90>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_neo4j = graph.run(\"\"\"\n",
    "MATCH edges = (a:TRANSACTION) --> (b:TRANSACTION)\n",
    "RETURN edges;\n",
    "\"\"\").to_subgraph()\n",
    "drawSubgraph(data_neo4j, options, height=\"500\", filename=\"advanced_example.html\", physics=physics, node_shape=node_shape, edge_width=3.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cypher (Naive Way)\n",
    "\n",
    "We can again apply the same query as above. The only slight adaption is the maximum length of the path which is increased to nine, the total number of nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Result] : {[ startID, length, path ]}\n",
      "{\n",
      "\t(1, 5, [1, 2, 6, 5, 1]),\n",
      "\t(1, 6, [1, 2, 9, 6, 5, 1]),\n",
      "\t(1, 6, [1, 3, 2, 6, 5, 1]),\n",
      "\t(1, 7, [1, 3, 2, 9, 6, 5, 1]),\n",
      "\t(1, 7, [1, 3, 8, 9, 6, 5, 1]),\n",
      "\t(2, 5, [2, 6, 5, 1, 2]),\n",
      "\t(2, 6, [2, 6, 5, 1, 3, 2]),\n",
      "\t(2, 6, [2, 9, 6, 5, 1, 2]),\n",
      "\t(2, 7, [2, 9, 6, 5, 1, 3, 2]),\n",
      "\t(3, 6, [3, 2, 6, 5, 1, 3]),\n",
      "\t(3, 7, [3, 2, 9, 6, 5, 1, 3]),\n",
      "\t(3, 7, [3, 8, 9, 6, 5, 1, 3]),\n",
      "\t(5, 5, [5, 1, 2, 6, 5]),\n",
      "\t(5, 6, [5, 1, 2, 9, 6, 5]),\n",
      "\t(5, 6, [5, 1, 3, 2, 6, 5]),\n",
      "\t(5, 7, [5, 1, 3, 2, 9, 6, 5]),\n",
      "\t(5, 7, [5, 1, 3, 8, 9, 6, 5]),\n",
      "\t(6, 5, [6, 5, 1, 2, 6]),\n",
      "\t(6, 6, [6, 5, 1, 2, 9, 6]),\n",
      "\t(6, 6, [6, 5, 1, 3, 2, 6]),\n",
      "\t(6, 7, [6, 5, 1, 3, 2, 9, 6]),\n",
      "\t(6, 7, [6, 5, 1, 3, 8, 9, 6]),\n",
      "\t(8, 7, [8, 9, 6, 5, 1, 3, 8]),\n",
      "\t(9, 6, [9, 6, 5, 1, 2, 9]),\n",
      "\t(9, 7, [9, 6, 5, 1, 3, 2, 9]),\n",
      "\t(9, 7, [9, 6, 5, 1, 3, 8, 9])\n",
      "}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vagrant/.conda/envs/bde/lib/python3.7/site-packages/py2neo/export.py:67: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  return array(list(map(list, cursor)), dtype=dtype, order=order)\n"
     ]
    }
   ],
   "source": [
    "cur = graph.run(\"\"\"\n",
    "MATCH cyclePath = (a:TRANSACTION) - [*..9] -> (a)\n",
    "WITH NODES(cyclePath) AS path\n",
    "RETURN path[0].node_id AS startID, SIZE(path) AS length, [n IN path | n.node_id] AS path;\n",
    "\"\"\")\n",
    "print_set_neo4j(cur)\n",
    "#cur.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cypher (Using Shortest Path)\n",
    "\n",
    "The previous query still depends on the manual adjustment of the maximal path length, but then returns all possible cycles up to this length. If we just want to know the shortest cycle per starting edge, we can adapt the query to use a shortest path algorithm which in addition removes the necessity to adapt the maximum path length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Result] : {[ startID, length, path ]}\n",
      "{\n",
      "\t(1, 6, [1, 3, 2, 6, 5, 1]),\n",
      "\t(1, 5, [1, 2, 6, 5, 1]),\n",
      "\t(2, 6, [2, 9, 6, 5, 1, 2]),\n",
      "\t(2, 5, [2, 6, 5, 1, 2]),\n",
      "\t(3, 7, [3, 8, 9, 6, 5, 1, 3]),\n",
      "\t(3, 6, [3, 2, 6, 5, 1, 3]),\n",
      "\t(5, 5, [5, 1, 2, 6, 5]),\n",
      "\t(6, 5, [6, 5, 1, 2, 6]),\n",
      "\t(8, 7, [8, 9, 6, 5, 1, 3, 8]),\n",
      "\t(9, 6, [9, 6, 5, 1, 2, 9])\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "cur = graph.run(\"\"\"\n",
    "MATCH (a:TRANSACTION)-->(b:TRANSACTION),\n",
    "  cyclePath=shortestPath((b)-[*]->(a))\n",
    "WITH [a] + NODES(cyclePath) AS path\n",
    "RETURN path[0].node_id AS startID, SIZE(path) AS length, [n IN path | n.node_id] AS path;\n",
    "\"\"\")\n",
    "print_set_neo4j(cur)\n",
    "#cur.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Topological Sort with Cypher\n",
    "\n",
    "Finding a topological order for a graph essentially consists of two steps:\n",
    "* Remove all cycles from the graph\n",
    "* Find one possible order by recursively eliminating nodes and edges"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove Cycles\n",
    "\n",
    "As we know from the previous queries that our graph does contain cycles, we first have to remove them. A naive approach could look like this: We eliminate nodes from the graph until there is no more cycle. To speed up the process, we start with the node connected to the most edges. To keep the graph intact, we do not actually remove the nodes, but mark them as removed instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reset removed flag for  9  nodes\n",
      "Graph contains cycle?  True\n",
      "Node to remove next:  1\n",
      "Removed?  True\n",
      "Graph contains cycle?  False\n",
      "Remaining graph:\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"400\"\n",
       "            src=\"pics/vis_generated/remaining_graph_acyclic.html\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7fee647afd90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Reset the removed flag (to the value false) for all nodes with label TRANSACTION\n",
    "# Return the number of affected nodes\n",
    "reset_removed_flag = \"\"\"\n",
    "MATCH (a:TRANSACTION)\n",
    "SET a.removed = false\n",
    "RETURN COUNT(a) AS count;\n",
    "\"\"\"\n",
    "\n",
    "# Check the graph for cycles, i.e. if we find a path starting at node a and leading back to node a\n",
    "# OPTIONAL MATCH ensures that the query returns a result even if we don't find such a path\n",
    "# The WHERE clause ensures that our path does not contain any node marked as removed\n",
    "# COALESCE returns the first non-NULL value and ensures that we get a boolean result \n",
    "# even if cyclePath (and therefore also LENGTH(cyclePath) is NULL)\n",
    "check_graph_for_cycles = \"\"\"\n",
    "OPTIONAL MATCH cyclePath = (a:TRANSACTION) - [*..9] -> (a)\n",
    "WHERE NOT ANY(n IN NODES(cyclePath) WHERE n.removed = true)\n",
    "RETURN COALESCE(LENGTH(cyclePath) > 0, false) AS cycle;\n",
    "\"\"\"\n",
    "\n",
    "# Count the number of edges (using size((a) -- ())) connected to each node and call it degree\n",
    "# Return the node ids ordered by decreasing degree\n",
    "nodes_by_num_edges = \"\"\"\n",
    "MATCH (a:TRANSACTION)\n",
    "WHERE a.removed = false\n",
    "WITH a, size((a) -- ()) AS degree\n",
    "RETURN a.node_id AS id\n",
    "ORDER BY degree DESC, a.node_id ASC;\n",
    "\"\"\"\n",
    "\n",
    "# Mark a node as removed by setting the removed property to true\n",
    "# The {} is a placeholder which will later be filled by a node_id using Python's string formatting\n",
    "mark_node_as_removed = \"\"\"\n",
    "MATCH (a:TRANSACTION)\n",
    "WHERE a.node_id = {}\n",
    "SET a.removed = true\n",
    "RETURN a.removed AS removed;\n",
    "\"\"\"\n",
    "\n",
    "# Retrieve the remaining graph for visulization\n",
    "# First get all non-removed nodes (the part up to the WITH)\n",
    "# Then use an OPTIONAL MATCH to find edges connecting them with some other non-removed nodes\n",
    "retrieve_remaining_graph = \"\"\"\n",
    "MATCH (a:TRANSACTION)\n",
    "WHERE a.removed = false\n",
    "WITH a\n",
    "OPTIONAL MATCH edges = (a) -- (b:TRANSACTION)\n",
    "WHERE b.removed = false\n",
    "RETURN a, b, edges;\n",
    "\"\"\"\n",
    "\n",
    "# First reset all removed flags\n",
    "# Then loop as long as we find cycles and remove them by eliminating nodes as described above\n",
    "num_nodes_resetted = graph.run(reset_removed_flag).data()[0]['count']\n",
    "print(\"Reset removed flag for \", num_nodes_resetted, \" nodes\")\n",
    "cycle = graph.run(check_graph_for_cycles).data()[0]['cycle']\n",
    "print(\"Graph contains cycle? \", cycle)\n",
    "while cycle:\n",
    "    top_node = graph.run(nodes_by_num_edges).data()[0]['id']\n",
    "    print(\"Node to remove next: \", top_node)\n",
    "    removed = graph.run(mark_node_as_removed.format(top_node)).data()[0]['removed']\n",
    "    print(\"Removed? \", removed)\n",
    "    cycle = graph.run(check_graph_for_cycles).data()[0]['cycle']\n",
    "    print(\"Graph contains cycle? \", cycle)\n",
    "\n",
    "print(\"Remaining graph:\\n\")\n",
    "data_neo4j = graph.run(retrieve_remaining_graph).to_subgraph()\n",
    "display(drawSubgraph(data_neo4j, options, height=\"400\", filename=\"remaining_graph_acyclic.html\", physics=physics, node_shape=node_shape, edge_width=3.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute Topological Order\n",
    "\n",
    "The topological order for an acyclic, directed graph can be computed by repeatedly applying the following steps as long as the graph still contains nodes:\n",
    "* Find all nodes with zero indegree, i.e. without incoming edge\n",
    "* Append these nodes to the topological order\n",
    "* Remove these nodes from the graph\n",
    "\n",
    "As in the previous step, we do not remove the nodes, but only mark them as removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nodes remaining:  8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"560\"\n",
       "            src=\"pics/vis_generated/remaining_graph_size8.html\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7fee647d6f90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing node  3\n",
      "\n",
      "Nodes remaining:  7\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"500\"\n",
       "            src=\"pics/vis_generated/remaining_graph_size7.html\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7fee6473b250>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing node  2\n",
      "Removing node  8\n",
      "\n",
      "Nodes remaining:  5\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"380\"\n",
       "            src=\"pics/vis_generated/remaining_graph_size5.html\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7fee64829690>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing node  9\n",
      "\n",
      "Nodes remaining:  4\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"320\"\n",
       "            src=\"pics/vis_generated/remaining_graph_size4.html\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7fee6482ca50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing node  6\n",
      "\n",
      "Nodes remaining:  3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"260\"\n",
       "            src=\"pics/vis_generated/remaining_graph_size3.html\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7fee647027d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing node  5\n",
      "\n",
      "Nodes remaining:  2\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"200\"\n",
       "            src=\"pics/vis_generated/remaining_graph_size2.html\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7fee647a5690>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing node  4\n",
      "\n",
      "Nodes remaining:  1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"140\"\n",
       "            src=\"pics/vis_generated/remaining_graph_size1.html\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7fee6473f2d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing node  7\n",
      "\n",
      "Nodes remaining:  0\n",
      "\n",
      "Final topological order:\n",
      " [3, 2, 8, 9, 6, 5, 4, 7]\n"
     ]
    }
   ],
   "source": [
    "# Mark a node as removed, see previous section\n",
    "mark_node_as_removed = \"\"\"\n",
    "MATCH (a:TRANSACTION)\n",
    "WHERE a.node_id = {}\n",
    "SET a.removed = true\n",
    "RETURN a.removed AS removed;\n",
    "\"\"\"\n",
    "\n",
    "# Get all nodes with zero indegree, i.e. without an incoming edge\n",
    "# First get all non-removed nodes (first part)\n",
    "# Then find and count all incoming edges per node (second part)\n",
    "# Finally return all nodes with zero incoming edges (third part)\n",
    "nodes_zero_indegree = \"\"\"\n",
    "MATCH (a:TRANSACTION)\n",
    "WHERE a.removed = false\n",
    "WITH a\n",
    "OPTIONAL MATCH (a) <-- (b:TRANSACTION)\n",
    "WHERE b.removed = false\n",
    "WITH a, COALESCE(COUNT(b), 0) AS size\n",
    "WHERE size = 0\n",
    "RETURN a.node_id AS id;\n",
    "\"\"\"\n",
    "\n",
    "# Count the number of remaining, i.e. non-removed nodes\n",
    "count_remaining_nodes = \"\"\"\n",
    "MATCH (a:TRANSACTION)\n",
    "WHERE a.removed = false\n",
    "RETURN COUNT(a) AS num;\n",
    "\"\"\"\n",
    "\n",
    "# Retrieve the remaining graph for visualization, see previous section\n",
    "retrieve_remaining_graph = \"\"\"\n",
    "MATCH (a:TRANSACTION)\n",
    "WHERE a.removed = false\n",
    "WITH a\n",
    "OPTIONAL MATCH edges = (a) -- (b:TRANSACTION)\n",
    "WHERE b.removed = false\n",
    "RETURN a, b, edges;\n",
    "\"\"\"\n",
    "\n",
    "# Loop as long as we still have nodes in our graph\n",
    "# Iteratively remove all nodes with zero indegree\n",
    "topological_order = []\n",
    "nodes_remaining = graph.run(count_remaining_nodes).data()[0]['num']\n",
    "print(\"Nodes remaining: \", nodes_remaining)\n",
    "while nodes_remaining > 0:\n",
    "    data_neo4j = graph.run(retrieve_remaining_graph).to_subgraph()\n",
    "    display(drawSubgraph(data_neo4j, options, height=str(nodes_remaining * 60 + 80), filename=\"remaining_graph_size{}.html\".format(nodes_remaining), physics=physics, node_shape=node_shape, edge_width=3.0))\n",
    "    next_nodes_zero_indegree = graph.run(nodes_zero_indegree).data()\n",
    "    for node in next_nodes_zero_indegree:\n",
    "        topological_order.append(node['id'])\n",
    "        removed = graph.run(mark_node_as_removed.format(node['id'])).data()[0]['removed']\n",
    "        print(\"Removing node \", node['id'])\n",
    "    nodes_remaining = graph.run(count_remaining_nodes).data()[0]['num']\n",
    "    print(\"\\nNodes remaining: \", nodes_remaining)\n",
    "\n",
    "print(\"\\nFinal topological order:\\n\", topological_order)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise\n",
    "\n",
    "The following exercise will operate on the IMDb database introduced in the beginning of the lecture series. It will be loaded into Neo4j below and consists of the following node and relationship types:\n",
    "* `ACTOR` nodes with attributes `node_id`, `first_name`, `last_name` and `gender`\n",
    "* `DIRECTOR` nodes with attributes `node_id`, `first_name` and `last_name`\n",
    "* `MOVIE` nodes with attributes `node_id`, `name`, `year` and `rank`\n",
    "* `GENRE` nodes with attributes `node_id` and `name`\n",
    "* `PLAYED_IN` relationship connecting actors to movies\n",
    "* `DIRECTED` relationship connecting directors to movies\n",
    "* `BELONGS_TO_GENRE` relationship connecting movies to genres\n",
    "\n",
    "Some hints:\n",
    "* Cypher uses the `=` operator for equality and the `<>` operator for inequality checks\n",
    "* Cypher provides similar aggregation functions as the SQL standard, especially `COUNT`, `SUM` and `AVG` which might be useful in some of the exercises\n",
    "* If you need to filter results based on an aggregate, use a combination of `WITH` and `WHERE` as it is shown in the `nodes_zero_indegree` query of the topological sort order section (you can ignore the `COALESCE` statement, it just ensures that 0 is returned if `COUNT(b)` returns `NULL`)\n",
    "* To generate a list of nodes from a path, use the `NODES(path)` operator. Combine it with the list comprehension syntax, e.g. shown in the naive cypher query for the basic precedence graph, to get a list of specific attributes per node.\n",
    "* `COUNT(DISTINCT p)` can be used to count the number of distinct paths contained in p\n",
    "* If an exercise asks for paths, you can assume undirected paths by default if the exercise does not specifically ask for directed paths.\n",
    "* For questions regarding the syntax, have a look at the examples above or the official [Cypher documentation](https://neo4j.com/docs/cypher-manual/current/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the IMDb example, nothing to do here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify paths to CSV files for social network\n",
    "imdb_actors_csv = \"./data/IMDb_sample/actors.csv\"\n",
    "imdb_directors_csv = \"./data/IMDb_sample/directors.csv\"\n",
    "imdb_movies_csv = \"./data/IMDb_sample/movies.csv\"\n",
    "imdb_movies_directors_csv = \"./data/IMDb_sample/movies_directors.csv\"\n",
    "imdb_movies_genres_csv = \"./data/IMDb_sample/movies_genres.csv\"\n",
    "imdb_roles_csv = \"./data/IMDb_sample/roles.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from py2neo import Node, Relationship\n",
    "\n",
    "# Reset exercise graph\n",
    "graph.run(\"MATCH (n:ACTOR) DETACH DELETE n;\")\n",
    "graph.run(\"MATCH (n:DIRECTOR) DETACH DELETE n;\")\n",
    "graph.run(\"MATCH (n:MOVIE) DETACH DELETE n;\")\n",
    "graph.run(\"MATCH (n:GENRE) DETACH DELETE n;\")\n",
    "\n",
    "# Create constraints on node_id\n",
    "graph.run(\"CREATE CONSTRAINT IF NOT EXISTS ON (n:ACTOR) ASSERT n.node_id IS UNIQUE;\")\n",
    "graph.run(\"CREATE CONSTRAINT IF NOT EXISTS ON (n:DIRECTOR) ASSERT n.node_id IS UNIQUE;\")\n",
    "graph.run(\"CREATE CONSTRAINT IF NOT EXISTS ON (n:MOVIE) ASSERT n.node_id IS UNIQUE;\")\n",
    "graph.run(\"CREATE CONSTRAINT IF NOT EXISTS ON (n:GENRE) ASSERT n.node_id IS UNIQUE;\")\n",
    "\n",
    "# Create nodes labelled with 'ACTOR'\n",
    "print(\"Creating actors...\")\n",
    "tx = graph.begin()\n",
    "actors_dict = {}\n",
    "with open(imdb_actors_csv, newline='') as csvfile:\n",
    "    csvreader = csv.DictReader(csvfile, delimiter=\"\\t\")\n",
    "    for row in csvreader:\n",
    "        actors_dict[int(row['id'])] = Node(\"ACTOR\", node_id=int(row['id']), first_name=str(row['first_name']), last_name=str(row['last_name']), gender=str(row['gender']))\n",
    "        tx.create(actors_dict[int(row['id'])])\n",
    "tx.commit()\n",
    "        \n",
    "# Create nodes labelled with 'DIRECTOR'\n",
    "print(\"Creating directors...\")\n",
    "tx = graph.begin()\n",
    "directors_dict = {}\n",
    "with open(imdb_directors_csv, newline='') as csvfile:\n",
    "    csvreader = csv.DictReader(csvfile, delimiter=\"\\t\")\n",
    "    for row in csvreader:\n",
    "        directors_dict[int(row['id'])] = Node(\"DIRECTOR\", node_id=int(row['id']), first_name=str(row['first_name']), last_name=str(row['last_name']))\n",
    "        tx.create(directors_dict[int(row['id'])])\n",
    "tx.commit()\n",
    "        \n",
    "# Create nodes labelled with 'MOVIE'\n",
    "print(\"Creating movies...\")\n",
    "tx = graph.begin()\n",
    "movies_dict = {}\n",
    "with open(imdb_movies_csv, newline='') as csvfile:\n",
    "    csvreader = csv.DictReader(csvfile, delimiter=\"\\t\")\n",
    "    for row in csvreader:\n",
    "        movies_dict[int(row['id'])] = Node(\"MOVIE\", node_id=int(row['id']), name=str(row['name']), year=int(row['year']), rank=float(row['rank']))\n",
    "        tx.create(movies_dict[int(row['id'])])\n",
    "tx.commit()\n",
    "        \n",
    "# Create nodes labelled with 'GENRE' and relationships labelled with 'BELONGS_TO_GENRE'\n",
    "print(\"Creating genres...\")\n",
    "tx = graph.begin()\n",
    "genres = set()\n",
    "genres_dict = {}\n",
    "with open(imdb_movies_genres_csv, newline='') as csvfile:\n",
    "    csvreader = csv.DictReader(csvfile, delimiter=\"\\t\")\n",
    "    for row in csvreader:\n",
    "        if not str(row['genre']) in genres:\n",
    "            genres_dict[str(row['genre'])] = Node(\"GENRE\", node_id=int(len(genres)), name=str(row['genre']))\n",
    "            tx.create(genres_dict[str(row['genre'])])\n",
    "            genres.add(str(row['genre']))\n",
    "        tx.create(Relationship(movies_dict[int(row['movie_id'])], \"BELONGS_TO_GENRE\", genres_dict[str(row['genre'])]))\n",
    "tx.commit()\n",
    "        \n",
    "# Create relationships labelled with 'PLAYED_IN'\n",
    "print(\"Creating relationship roles...\")\n",
    "tx = graph.begin()\n",
    "with open(imdb_roles_csv, newline='') as csvfile:\n",
    "    csvreader = csv.DictReader(csvfile, delimiter=\"\\t\")\n",
    "    for row in csvreader:\n",
    "        tx.create(Relationship(actors_dict[int(row['actor_id'])], \"PLAYED_IN\", movies_dict[int(row['movie_id'])], role=str(row['role'])))\n",
    "tx.commit()\n",
    "        \n",
    "# Create relationships labelled with 'DIRECTED'\n",
    "print(\"Creating relationship directors...\")\n",
    "tx = graph.begin()\n",
    "with open(imdb_movies_directors_csv, newline='') as csvfile:\n",
    "    csvreader = csv.DictReader(csvfile, delimiter=\"\\t\")\n",
    "    for row in csvreader:\n",
    "        tx.create(Relationship(directors_dict[int(row['director_id'])], \"DIRECTED\", movies_dict[int(row['movie_id'])]))\n",
    "tx.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1\n",
    "\n",
    "Compute the number of distinct movies which have a director whose name is not Quentin Tarantino. Rename the result to `num`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write your query here\n",
    "query_student_1 = \"\"\"\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test, do not modify\n",
    "cur = graph.run(query_student_1)\n",
    "data_dict_student_1 = cur.data()\n",
    "    \n",
    "with open(\"./data/cypher/tests/query1.csv\", newline='') as csvfile:\n",
    "    csvreader = csv.DictReader(csvfile)\n",
    "    data_dict_result_1 = []\n",
    "    for row in csvreader:\n",
    "        data_dict_result_1.append(row)\n",
    "    assert len(data_dict_result_1) == len(data_dict_student_1), \"expected: \" + str(len(data_dict_result_1)) + \" entries, got: \" + str(len(data_dict_student_1))\n",
    "    for i in range(len(data_dict_result_1)):\n",
    "        assert 'num' in data_dict_student_1[i], \"output field 'num' missing\"\n",
    "        assert int(data_dict_result_1[i]['num']) == int(data_dict_student_1[i]['num']), \"expected: \" + str(data_dict_result_1[i]['num']) + \", got: \" + str(data_dict_student_1[i]['num'])\n",
    "print(\"Your query passed this test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2\n",
    "\n",
    "Return the average rank of all movies directed by Stanley Kubrick having more than 5 actors. Rename the output to `avgRank`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write your query here\n",
    "query_student_2 = \"\"\"\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test, do not modify\n",
    "cur = graph.run(query_student_2)\n",
    "data_dict_student_2 = cur.data()\n",
    "    \n",
    "with open(\"./data/cypher/tests/query2.csv\", newline='') as csvfile:\n",
    "    csvreader = csv.DictReader(csvfile)\n",
    "    data_dict_result_2 = []\n",
    "    for row in csvreader:\n",
    "        data_dict_result_2.append(row)\n",
    "    assert len(data_dict_result_2) == len(data_dict_student_2), \"expected: \" + str(len(data_dict_result_2)) + \" entries, got: \" + str(len(data_dict_student_2))\n",
    "    for i in range(len(data_dict_result_2)):\n",
    "        assert 'avgRank' in data_dict_student_2[i], \"output field 'avgRank' missing\"\n",
    "        assert round(float(data_dict_result_2[i]['avgRank']), 6) == round(float(data_dict_student_2[i]['avgRank']), 6), \"expected: \" + str(round(float(data_dict_result_2[i]['avgRank']), 6)) + \", got: \" + str(round(float(data_dict_student_2[i]['avgRank']), 6))\n",
    "print(\"Your query passed this test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3\n",
    "\n",
    "Compute the number of distinct paths of minimal length 2 and maximal length 5 between the two actors Sally Ricca and Martin Jarvis. Rename the output to `numPaths`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write your query here\n",
    "query_student_3 = \"\"\"\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test, do not modify\n",
    "cur = graph.run(query_student_3)\n",
    "data_dict_student_3 = cur.data()\n",
    "    \n",
    "with open(\"./data/cypher/tests/query5.csv\", newline='') as csvfile:\n",
    "    csvreader = csv.DictReader(csvfile)\n",
    "    data_dict_result_3 = []\n",
    "    for row in csvreader:\n",
    "        data_dict_result_3.append(row)\n",
    "    assert len(data_dict_result_3) == len(data_dict_student_3), \"expected: \" + str(len(data_dict_result_3)) + \" entries, got: \" + str(len(data_dict_student_3))\n",
    "    for i in range(len(data_dict_result_3)):\n",
    "        assert 'numPaths' in data_dict_student_3[i], \"output field 'numPaths' missing\"\n",
    "        assert int(data_dict_result_3[i]['numPaths']) == int(data_dict_student_3[i]['numPaths']), \"expected: \" + str(data_dict_result_3[i]['numPaths']) + \", got: \" + str(data_dict_student_3[i]['numPaths'])\n",
    "print(\"Your query passed this test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 4\n",
    "\n",
    "Compute the shortest path between the two actors Ken Gibbel and Vince Pace. Return the path as a list of `node_id` (the id of each node contained in the path) and rename it to `shortestPath`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write your query here\n",
    "query_student_4 = \"\"\"\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test, do not modify\n",
    "cur = graph.run(query_student_4)\n",
    "data_dict_student_4 = cur.data()\n",
    "\n",
    "with open(\"./data/cypher/tests/query6.csv\", newline='') as csvfile:\n",
    "    csvreader = csv.DictReader(csvfile, delimiter='\\t')\n",
    "    data_dict_result_4 = []\n",
    "    for row in csvreader:\n",
    "        data_dict_result_4.append(row)\n",
    "    assert len(data_dict_result_4) == len(data_dict_student_4), \"expected: \" + str(len(data_dict_result_4)) + \" entries, got: \" + str(len(data_dict_student_4))\n",
    "    for i in range(len(data_dict_result_4)):\n",
    "        assert 'shortestPath' in data_dict_student_4[i], \"output field 'shortestPath' missing\"\n",
    "        assert str(data_dict_result_4[i]['shortestPath']) == str(data_dict_student_4[i]['shortestPath']), \"expected: \" + str(data_dict_result_4[i]['shortestPath']) + \", got: \" + str(data_dict_student_4[i]['shortestPath'])\n",
    "print(\"Your query passed this test\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
