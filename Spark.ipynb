{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright Felix Martin Schuhknecht, Jens Dittrich & Marcel Maltry  [Big Data Analytics Group](https://bigdata.uni-saarland.de/), [CC-BY-SA](https://creativecommons.org/licenses/by-sa/4.0/legalcode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following notebook was tested with Spark 3.0.2 and requires `SPARK_HOME` to be set to the Spark path."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Couldn't find Spark, make sure SPARK_HOME env is set or Spark is in an expected location (e.g. from homebrew installation).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-b8deb442aee4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mra\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelation\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mRelation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mos\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlistdir\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mra\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moperators_spark\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/shared/bigdataengineering/ra/operators_spark.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# Spark Imports\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfindspark\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mfindspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpyspark\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpyspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msql\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSparkSession\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/bde/lib/python3.7/site-packages/findspark.py\u001b[0m in \u001b[0;36minit\u001b[0;34m(spark_home, python_path, edit_rc, edit_profile)\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mspark_home\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m         \u001b[0mspark_home\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mpython_path\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/bde/lib/python3.7/site-packages/findspark.py\u001b[0m in \u001b[0;36mfind\u001b[0;34m()\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mspark_home\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m         raise ValueError(\"Couldn't find Spark, make sure SPARK_HOME env is set\"\n\u001b[0m\u001b[1;32m     34\u001b[0m                          \" or Spark is in an expected location (e.g. from homebrew installation).\")\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Couldn't find Spark, make sure SPARK_HOME env is set or Spark is in an expected location (e.g. from homebrew installation)."
     ]
    }
   ],
   "source": [
    "import os\n",
    "from graphviz import Digraph, Source\n",
    "from ra.relation import Relation\n",
    "from os import listdir\n",
    "from ra.operators_spark import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a new Spark session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spark Version: 2.4.5\n"
     ]
    }
   ],
   "source": [
    "session = SparkSession.builder.getOrCreate()\n",
    "print(\"Spark Version: \" + session.version)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'movies_directors': <ra.relation.Relation object at 0x7f04b2553290>, 'actors': <ra.relation.Relation object at 0x7f04b2553450>, 'directors': <ra.relation.Relation object at 0x7f04b2315fd0>, 'movies_genres': <ra.relation.Relation object at 0x7f04b23172d0>, 'directors_genres': <ra.relation.Relation object at 0x7f04b2319dd0>, 'movies': <ra.relation.Relation object at 0x7f04b231c8d0>, 'roles': <ra.relation.Relation object at 0x7f04b231cfd0>}\n"
     ]
    }
   ],
   "source": [
    "# Data source: https://relational.fit.cvut.cz/dataset/IMDb\n",
    "# Information courtesy of IMDb (http://www.imdb.com). Used with permission.\n",
    "# Notice: The data can only be used for personal and non-commercial use and must not\n",
    "# be altered/republished/resold/repurposed to create any kind of online/offline\n",
    "# database of movie information (except for individual personal use).\n",
    "\n",
    "path = 'data/IMDb_sample'  \n",
    "# create a list of all files in that directory that end with \"*.csv\":\n",
    "files = [file for file in listdir(path) if file.endswith('.csv')]\n",
    "\n",
    "from ra.utils import load_csv\n",
    "\n",
    "relations = [load_csv(path + '/' + file, file[:-4], delimiter='\\t') for file in files]\n",
    "\n",
    "relationsDict = {}\n",
    "for rel in relations:\n",
    "    relationsDict[rel.name] = rel\n",
    "print(relationsDict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We build LeafSpark objects from existing relations. Each LeafSpark object contains the data in form of a Spark DataFrame. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build LeafRelation object from relations dictionary\n",
    "movies_directors = LeafSpark(relationsDict['movies_directors'], session)\n",
    "actors = LeafSpark(relationsDict['actors'], session)\n",
    "directors = LeafSpark(relationsDict['directors'], session)\n",
    "movies_genres = LeafSpark(relationsDict['movies_genres'], session)\n",
    "directors_genres = LeafSpark(relationsDict['directors_genres'], session)\n",
    "movies = LeafSpark(relationsDict['movies'], session)\n",
    "roles = LeafSpark(relationsDict['roles'], session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----------+---------+\n",
      "|   id|first_name|last_name|\n",
      "+-----+----------+---------+\n",
      "|78273|   Quentin|Tarantino|\n",
      "|43095|   Stanley|  Kubrick|\n",
      "|11652| James (I)|  Cameron|\n",
      "+-----+----------+---------+\n",
      "\n",
      "root\n",
      " |-- id: integer (nullable = false)\n",
      " |-- first_name: string (nullable = false)\n",
      " |-- last_name: string (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "directors.evaluate().show()\n",
    "directors.evaluate().printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "newmovies = Selection_Spark(movies, 'year>2000')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------------+----+----+\n",
      "|    id|                name|year|rank|\n",
      "+------+--------------------+----+----+\n",
      "|127297| Ghosts of the Abyss|2003| 6.7|\n",
      "| 10934|  Aliens of the Deep|2005| 6.5|\n",
      "|176712|   Kill Bill: Vol. 2|2004| 8.2|\n",
      "|393538|  Jimmy Kimmel Live!|2003| 6.7|\n",
      "|176711|   Kill Bill: Vol. 1|2003| 8.4|\n",
      "|105938|Expedition: Bismarck|2002| 7.5|\n",
      "|159665| Inglorious Bastards|2006| 8.3|\n",
      "| 96779|        Earthship.TV|2001| 5.6|\n",
      "+------+--------------------+----+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "newmovies.evaluate().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp2 = Projection_Spark(newmovies, 'id, year')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----+\n",
      "|    id|year|\n",
      "+------+----+\n",
      "|127297|2003|\n",
      "| 10934|2005|\n",
      "|176712|2004|\n",
      "|393538|2003|\n",
      "|176711|2003|\n",
      "|105938|2002|\n",
      "|159665|2006|\n",
      "| 96779|2001|\n",
      "+------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "exp2.evaluate().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cartesian Product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "cartesianProduct = Cartesian_Product_Spark(directors, directors_genres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----------+---------+\n",
      "|   id|first_name|last_name|\n",
      "+-----+----------+---------+\n",
      "|78273|   Quentin|Tarantino|\n",
      "|43095|   Stanley|  Kubrick|\n",
      "|11652| James (I)|  Cameron|\n",
      "+-----+----------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "directors.evaluate().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----------+---------+\n",
      "|director_id|      genre|     prob|\n",
      "+-----------+-----------+---------+\n",
      "|      43095|     Horror|   0.0625|\n",
      "|      11652|Documentary|     0.25|\n",
      "|      43095|     Action|   0.0625|\n",
      "|      78273|   Thriller|      0.5|\n",
      "|      78273|    Romance|    0.125|\n",
      "|      11652|    Romance|     0.25|\n",
      "|      43095|   Thriller|   0.1875|\n",
      "|      11652|     Sci-Fi|      0.5|\n",
      "|      43095|      Short|   0.1875|\n",
      "|      43095|    Romance|   0.1875|\n",
      "|      43095|  Adventure|   0.0625|\n",
      "|      78273|     Comedy|     0.25|\n",
      "|      11652|     Action|      0.5|\n",
      "|      78273|    Mystery|    0.125|\n",
      "|      11652|      Short|     0.25|\n",
      "|      11652|     Family|0.0833333|\n",
      "|      43095|      Crime|   0.1875|\n",
      "|      11652|    Fantasy|0.0833333|\n",
      "|      11652|     Comedy|0.0833333|\n",
      "|      11652|     Horror| 0.166667|\n",
      "+-----------+-----------+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "directors_genres.evaluate().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----------+---------+-----------+-----------+------+\n",
      "|   id|first_name|last_name|director_id|      genre|  prob|\n",
      "+-----+----------+---------+-----------+-----------+------+\n",
      "|78273|   Quentin|Tarantino|      43095|     Horror|0.0625|\n",
      "|78273|   Quentin|Tarantino|      11652|Documentary|  0.25|\n",
      "|78273|   Quentin|Tarantino|      43095|     Action|0.0625|\n",
      "|78273|   Quentin|Tarantino|      78273|   Thriller|   0.5|\n",
      "|78273|   Quentin|Tarantino|      78273|    Romance| 0.125|\n",
      "|78273|   Quentin|Tarantino|      11652|    Romance|  0.25|\n",
      "|78273|   Quentin|Tarantino|      43095|   Thriller|0.1875|\n",
      "|78273|   Quentin|Tarantino|      11652|     Sci-Fi|   0.5|\n",
      "|78273|   Quentin|Tarantino|      43095|      Short|0.1875|\n",
      "|78273|   Quentin|Tarantino|      43095|    Romance|0.1875|\n",
      "+-----+----------+---------+-----------+-----------+------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cartesianProduct.evaluate().show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intersection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "goodmovies = Selection_Spark(movies, \"rank>=7.5\")\n",
    "goodAndNew = Intersection_Spark(newmovies, goodmovies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------------+----+----+\n",
      "|    id|                name|year|rank|\n",
      "+------+--------------------+----+----+\n",
      "|176711|   Kill Bill: Vol. 1|2003| 8.4|\n",
      "|105938|Expedition: Bismarck|2002| 7.5|\n",
      "|159665| Inglorious Bastards|2006| 8.3|\n",
      "|176712|   Kill Bill: Vol. 2|2004| 8.2|\n",
      "+------+--------------------+----+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "goodAndNew.evaluate().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, without intersection but with two conditions in the selection instead:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "goodAndNewSel = Selection_Spark(movies, \"year>2000 and rank>=7.5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------------+----+----+\n",
      "|    id|                name|year|rank|\n",
      "+------+--------------------+----+----+\n",
      "|176712|   Kill Bill: Vol. 2|2004| 8.2|\n",
      "|176711|   Kill Bill: Vol. 1|2003| 8.4|\n",
      "|105938|Expedition: Bismarck|2002| 7.5|\n",
      "|159665| Inglorious Bastards|2006| 8.3|\n",
      "+------+--------------------+----+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "goodAndNewSel.evaluate().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Union"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "goodOrNew = Union_Spark(goodmovies, newmovies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------------+----+----+\n",
      "|    id|                name|year|rank|\n",
      "+------+--------------------+----+----+\n",
      "|121538|   Full Metal Jacket|1987| 8.2|\n",
      "|  1711|2001: A Space Ody...|1968| 8.3|\n",
      "|177019|        Killing, The|1956| 8.1|\n",
      "|328285|     Terminator, The|1984| 7.9|\n",
      "|276217|      Reservoir Dogs|1992| 8.3|\n",
      "| 65764| Clockwork Orange, A|1971| 8.3|\n",
      "|164572|        Jackie Brown|1997| 7.5|\n",
      "| 10920|              Aliens|1986| 8.2|\n",
      "|387728|                  ER|1994| 7.7|\n",
      "|299073|        Shining, The|1980| 8.2|\n",
      "| 92616|Dr. Strangelove o...|1964| 8.7|\n",
      "|310455|           Spartacus|1960| 8.0|\n",
      "|176712|   Kill Bill: Vol. 2|2004| 8.2|\n",
      "|267038|        Pulp Fiction|1994| 8.7|\n",
      "|193519|              Lolita|1962| 7.6|\n",
      "|328277|Terminator 2: Jud...|1991| 8.1|\n",
      "|176711|   Kill Bill: Vol. 1|2003| 8.4|\n",
      "|105938|Expedition: Bismarck|2002| 7.5|\n",
      "|159665| Inglorious Bastards|2006| 8.3|\n",
      "|250612|      Paths of Glory|1957| 8.6|\n",
      "+------+--------------------+----+----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "goodOrNew.evaluate().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, without union but with two conditions in the selection instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "goodOrNewSel = Selection_Spark(movies, \"year>2000 or rank>=7.5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------------+----+----+\n",
      "|    id|                name|year|rank|\n",
      "+------+--------------------+----+----+\n",
      "|121538|   Full Metal Jacket|1987| 8.2|\n",
      "|  1711|2001: A Space Ody...|1968| 8.3|\n",
      "|177019|        Killing, The|1956| 8.1|\n",
      "|328285|     Terminator, The|1984| 7.9|\n",
      "|276217|      Reservoir Dogs|1992| 8.3|\n",
      "| 65764| Clockwork Orange, A|1971| 8.3|\n",
      "|164572|        Jackie Brown|1997| 7.5|\n",
      "| 10920|              Aliens|1986| 8.2|\n",
      "|127297| Ghosts of the Abyss|2003| 6.7|\n",
      "|387728|                  ER|1994| 7.7|\n",
      "|299073|        Shining, The|1980| 8.2|\n",
      "| 92616|Dr. Strangelove o...|1964| 8.7|\n",
      "| 10934|  Aliens of the Deep|2005| 6.5|\n",
      "|310455|           Spartacus|1960| 8.0|\n",
      "|176712|   Kill Bill: Vol. 2|2004| 8.2|\n",
      "|393538|  Jimmy Kimmel Live!|2003| 6.7|\n",
      "|267038|        Pulp Fiction|1994| 8.7|\n",
      "|193519|              Lolita|1962| 7.6|\n",
      "|328277|Terminator 2: Jud...|1991| 8.1|\n",
      "|176711|   Kill Bill: Vol. 1|2003| 8.4|\n",
      "+------+--------------------+----+----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "goodOrNewSel.evaluate().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "newButBadMovies = Difference_Spark(newmovies, goodmovies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------------------+----+----+\n",
      "|    id|               name|year|rank|\n",
      "+------+-------------------+----+----+\n",
      "|393538| Jimmy Kimmel Live!|2003| 6.7|\n",
      "|127297|Ghosts of the Abyss|2003| 6.7|\n",
      "| 10934| Aliens of the Deep|2005| 6.5|\n",
      "| 96779|       Earthship.TV|2001| 5.6|\n",
      "+------+-------------------+----+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "newButBadMovies.evaluate().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, without intersection but with two conditions in the selection instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "newButBadMoviesSel = Selection_Spark(movies, \"year>2000 and not rank>=7.5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------------------+----+----+\n",
      "|    id|               name|year|rank|\n",
      "+------+-------------------+----+----+\n",
      "|127297|Ghosts of the Abyss|2003| 6.7|\n",
      "| 10934| Aliens of the Deep|2005| 6.5|\n",
      "|393538| Jimmy Kimmel Live!|2003| 6.7|\n",
      "| 96779|       Earthship.TV|2001| 5.6|\n",
      "+------+-------------------+----+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "newButBadMoviesSel.evaluate().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Renaming Relation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataFrames do not have a name. Thus, renaming has no effect\n",
    "exp11 = Renaming_Relation_Spark(goodOrNew, \"good_or_new\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------------+----+----+\n",
      "|    id|                name|year|rank|\n",
      "+------+--------------------+----+----+\n",
      "|121538|   Full Metal Jacket|1987| 8.2|\n",
      "|  1711|2001: A Space Ody...|1968| 8.3|\n",
      "|177019|        Killing, The|1956| 8.1|\n",
      "|328285|     Terminator, The|1984| 7.9|\n",
      "|276217|      Reservoir Dogs|1992| 8.3|\n",
      "| 65764| Clockwork Orange, A|1971| 8.3|\n",
      "|164572|        Jackie Brown|1997| 7.5|\n",
      "| 10920|              Aliens|1986| 8.2|\n",
      "|387728|                  ER|1994| 7.7|\n",
      "|299073|        Shining, The|1980| 8.2|\n",
      "| 92616|Dr. Strangelove o...|1964| 8.7|\n",
      "|310455|           Spartacus|1960| 8.0|\n",
      "|176712|   Kill Bill: Vol. 2|2004| 8.2|\n",
      "|267038|        Pulp Fiction|1994| 8.7|\n",
      "|193519|              Lolita|1962| 7.6|\n",
      "|328277|Terminator 2: Jud...|1991| 8.1|\n",
      "|176711|   Kill Bill: Vol. 1|2003| 8.4|\n",
      "|105938|Expedition: Bismarck|2002| 7.5|\n",
      "|159665| Inglorious Bastards|2006| 8.3|\n",
      "|250612|      Paths of Glory|1957| 8.6|\n",
      "+------+--------------------+----+----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "exp11.evaluate().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Renaming Attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp12 = Renaming_Attributes_Spark(exp11, 'movies<-name, published<-year')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------+\n",
      "|              movies|published|\n",
      "+--------------------+---------+\n",
      "|   Full Metal Jacket|     1987|\n",
      "|2001: A Space Ody...|     1968|\n",
      "|        Killing, The|     1956|\n",
      "|     Terminator, The|     1984|\n",
      "|      Reservoir Dogs|     1992|\n",
      "| Clockwork Orange, A|     1971|\n",
      "|        Jackie Brown|     1997|\n",
      "|              Aliens|     1986|\n",
      "|                  ER|     1994|\n",
      "|        Shining, The|     1980|\n",
      "|Dr. Strangelove o...|     1964|\n",
      "|           Spartacus|     1960|\n",
      "|   Kill Bill: Vol. 2|     2004|\n",
      "|        Pulp Fiction|     1994|\n",
      "|              Lolita|     1962|\n",
      "|Terminator 2: Jud...|     1991|\n",
      "|   Kill Bill: Vol. 1|     2003|\n",
      "|Expedition: Bismarck|     2002|\n",
      "| Inglorious Bastards|     2006|\n",
      "|      Paths of Glory|     1957|\n",
      "+--------------------+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "exp12.evaluate().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Theta Join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "directorsAndTheirMovies = Theta_Join_Spark(directors, movies_directors, \"id==director_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----------+---------+-----------+--------+\n",
      "|   id|first_name|last_name|director_id|movie_id|\n",
      "+-----+----------+---------+-----------+--------+\n",
      "|43095|   Stanley|  Kubrick|      43095|   30431|\n",
      "|43095|   Stanley|  Kubrick|      43095|   92616|\n",
      "|43095|   Stanley|  Kubrick|      43095|    1711|\n",
      "|43095|   Stanley|  Kubrick|      43095|  176891|\n",
      "|43095|   Stanley|  Kubrick|      43095|  110246|\n",
      "|43095|   Stanley|  Kubrick|      43095|  177019|\n",
      "|43095|   Stanley|  Kubrick|      43095|   65764|\n",
      "|43095|   Stanley|  Kubrick|      43095|  106666|\n",
      "|43095|   Stanley|  Kubrick|      43095|  121538|\n",
      "|43095|   Stanley|  Kubrick|      43095|  310455|\n",
      "+-----+----------+---------+-----------+--------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "directorsAndTheirMovies.evaluate().show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grouping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Idea: count the number of female/male actors\n",
    "\n",
    "# grouping key: ['gender']\n",
    "# aggregation function: len (also called count)\n",
    "# notice that for len() specifying an attribute is actually not required\n",
    "# as only the number of tuples in each group are coiunted\n",
    "# this is independent of a specific attribute value\n",
    "grouping = Grouping_Spark(actors, 'gender', 'count(*)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------+\n",
      "|gender|count(1)|\n",
      "+------+--------+\n",
      "|     F|     289|\n",
      "|     M|     802|\n",
      "+------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "grouping.evaluate().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Idea: group on multiple attributes\n",
    "grouping = Grouping_Spark(actors, 'first_name, last_name', 'count(*)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+---------+--------+\n",
      "| first_name|last_name|count(1)|\n",
      "+-----------+---------+--------+\n",
      "|        Joe|   Morton|       1|\n",
      "|   John (I)|    Gavin|       1|\n",
      "|       John|     Lees|       1|\n",
      "| Daniel (I)|  Richter|       1|\n",
      "|        Dan|  Stanton|       1|\n",
      "|      Genya|Chernaiev|       1|\n",
      "|     Dorian| Harewood|       1|\n",
      "|   Kirk (I)|  Douglas|       1|\n",
      "|  David (I)|   Milner|       1|\n",
      "|       Gary| Cockrell|       1|\n",
      "|       Gaye|    Brown|       1|\n",
      "|      Grant|   Heslov|       1|\n",
      "|       Rudy|  Joffroy|       1|\n",
      "|       Mike|   Lovell|       1|\n",
      "|      Peter|   Schrum|       1|\n",
      "| Robert (I)|  Forster|       1|\n",
      "|     Hal J.|    Moore|       1|\n",
      "|   Dick (I)|   Miller|       1|\n",
      "|Justin (II)|    Baker|       1|\n",
      "|      Carey|   Loftin|       1|\n",
      "+-----------+---------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "grouping.evaluate().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query Optimization in Spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spark SQL implements its own query optimizer. It performs the following steps:\n",
    "1. Parse the query and generate the logical plan.\n",
    "2. Analyze the logical plan. In this step, the schema is checked and types are resolved.\n",
    "3. Optimize the logical plan using rule-based optimization, e.g. by applying selection push-down\n",
    "4. Generate multiple possible physical plans and pick the cheapest one with respect to a cost-model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# spark plan \n",
    "cp = Cartesian_Product_Spark(directors, directors_genres)\n",
    "sel1 = Selection_Spark(cp, \"id == director_id\")\n",
    "sel2 = Selection_Spark(sel1, \"last_name == 'Tarantino' and genre == 'Mystery'\")\n",
    "proj = Projection_Spark(sel2, 'last_name, prob')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Parsed Logical Plan ==\n",
      "'Project [unresolvedalias('last_name, None), unresolvedalias('prob, None)]\n",
      "+- Filter ((last_name#14 = Tarantino) && (genre#23 = Mystery))\n",
      "   +- Filter (id#12 = director_id#22)\n",
      "      +- Join Cross\n",
      "         :- LogicalRDD [id#12, first_name#13, last_name#14], false\n",
      "         +- LogicalRDD [director_id#22, genre#23, prob#24], false\n",
      "\n",
      "== Analyzed Logical Plan ==\n",
      "last_name: string, prob: float\n",
      "Project [last_name#14, prob#24]\n",
      "+- Filter ((last_name#14 = Tarantino) && (genre#23 = Mystery))\n",
      "   +- Filter (id#12 = director_id#22)\n",
      "      +- Join Cross\n",
      "         :- LogicalRDD [id#12, first_name#13, last_name#14], false\n",
      "         +- LogicalRDD [director_id#22, genre#23, prob#24], false\n",
      "\n",
      "== Optimized Logical Plan ==\n",
      "Project [last_name#14, prob#24]\n",
      "+- Join Cross, (id#12 = director_id#22)\n",
      "   :- Project [id#12, last_name#14]\n",
      "   :  +- Filter (last_name#14 = Tarantino)\n",
      "   :     +- LogicalRDD [id#12, first_name#13, last_name#14], false\n",
      "   +- Project [director_id#22, prob#24]\n",
      "      +- Filter (genre#23 = Mystery)\n",
      "         +- LogicalRDD [director_id#22, genre#23, prob#24], false\n",
      "\n",
      "== Physical Plan ==\n",
      "*(5) Project [last_name#14, prob#24]\n",
      "+- *(5) SortMergeJoin [id#12], [director_id#22], Cross\n",
      "   :- *(2) Sort [id#12 ASC NULLS FIRST], false, 0\n",
      "   :  +- Exchange hashpartitioning(id#12, 200)\n",
      "   :     +- *(1) Project [id#12, last_name#14]\n",
      "   :        +- *(1) Filter (last_name#14 = Tarantino)\n",
      "   :           +- Scan ExistingRDD[id#12,first_name#13,last_name#14]\n",
      "   +- *(4) Sort [director_id#22 ASC NULLS FIRST], false, 0\n",
      "      +- Exchange hashpartitioning(director_id#22, 200)\n",
      "         +- *(3) Project [director_id#22, prob#24]\n",
      "            +- *(3) Filter (genre#23 = Mystery)\n",
      "               +- Scan ExistingRDD[director_id#22,genre#23,prob#24]\n"
     ]
    }
   ],
   "source": [
    "# print logical and physical plan\n",
    "proj.evaluate().explain(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logical to Spark Plan Compilation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----+\n",
      "|last_name| prob|\n",
      "+---------+-----+\n",
      "|Tarantino|0.125|\n",
      "+---------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# one to one translation from our logical operators to our spark operators.\n",
    "def logical_to_spark(op):\n",
    "    if(isinstance(op, LeafOperator)): return LeafSpark(op.relation, session)\n",
    "    elif(isinstance(op, Selection)): return Selection_Spark(op.input, op.predicate)\n",
    "    elif(isinstance(op, Projection)): return Projection_Spark(op.input, ','.join(op.attributes))\n",
    "    elif(isinstance(op, Cartesian_Product)): return Cartesian_Product_Spark(op.l_input, op.r_input) \n",
    "    elif(isinstance(op, SetOperator)): return SetOperator_Spark(op.l_input, op.r_input, op.operator, op.symbol)\n",
    "    elif(isinstance(op, Renaming_Relation)): return Renaming_Relation_Spark(op.input, op.name)\n",
    "    elif(isinstance(op, Renaming_Attributes)): return Renaming_Attributes_Spark(op.input, op.changes) \n",
    "    elif(isinstance(op, Theta_Join)): return Theta_Join_Spark(op.l_input, op.r_input, op.theta) \n",
    "    elif(isinstance(op, Equi_Join)): return Equi_Join_Spark(op.l_input, op.r_input, op.l_attrs, op.r_attrs)\n",
    "    elif(isinstance(op, Grouping)): return Grouping_Spark(op.input, op.group_by, op.aggregations)    \n",
    "    else: return None\n",
    "\n",
    "# compile a logical operator tree to a spark operator tree\n",
    "def compile_to_spark(op):\n",
    "    new_op = logical_to_spark(op)\n",
    "    if(isinstance(op, UnaryOperator)):\n",
    "        new_op.input = compile_to_spark(op.input)\n",
    "    elif(isinstance(op, BinaryOperator)):\n",
    "        new_op.l_input = compile_to_spark(op.l_input)\n",
    "        new_op.r_input = compile_to_spark(op.r_input)\n",
    "    return new_op\n",
    "\n",
    "# logical plan\n",
    "cp = Cartesian_Product(directors, directors_genres)\n",
    "sel1 = Selection(cp, \"id == director_id\")\n",
    "sel2 = Selection(sel1, \"last_name == 'Tarantino' and genre == 'Mystery'\")\n",
    "proj = Projection(sel2, 'last_name, prob')\n",
    "\n",
    "# compile\n",
    "phys_root = compile_to_spark(proj)\n",
    "\n",
    "# run \n",
    "phys_root.evaluate().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Parsed Logical Plan ==\n",
      "'Project [unresolvedalias('last_name, None), unresolvedalias('prob, None)]\n",
      "+- Filter ((last_name#339 = Tarantino) && (genre#344 = Mystery))\n",
      "   +- Filter (id#337 = director_id#343)\n",
      "      +- Join Cross\n",
      "         :- LogicalRDD [id#337, first_name#338, last_name#339], false\n",
      "         +- LogicalRDD [director_id#343, genre#344, prob#345], false\n",
      "\n",
      "== Analyzed Logical Plan ==\n",
      "last_name: string, prob: float\n",
      "Project [last_name#339, prob#345]\n",
      "+- Filter ((last_name#339 = Tarantino) && (genre#344 = Mystery))\n",
      "   +- Filter (id#337 = director_id#343)\n",
      "      +- Join Cross\n",
      "         :- LogicalRDD [id#337, first_name#338, last_name#339], false\n",
      "         +- LogicalRDD [director_id#343, genre#344, prob#345], false\n",
      "\n",
      "== Optimized Logical Plan ==\n",
      "Project [last_name#339, prob#345]\n",
      "+- Join Cross, (id#337 = director_id#343)\n",
      "   :- Project [id#337, last_name#339]\n",
      "   :  +- Filter (last_name#339 = Tarantino)\n",
      "   :     +- LogicalRDD [id#337, first_name#338, last_name#339], false\n",
      "   +- Project [director_id#343, prob#345]\n",
      "      +- Filter (genre#344 = Mystery)\n",
      "         +- LogicalRDD [director_id#343, genre#344, prob#345], false\n",
      "\n",
      "== Physical Plan ==\n",
      "*(5) Project [last_name#339, prob#345]\n",
      "+- *(5) SortMergeJoin [id#337], [director_id#343], Cross\n",
      "   :- *(2) Sort [id#337 ASC NULLS FIRST], false, 0\n",
      "   :  +- Exchange hashpartitioning(id#337, 200)\n",
      "   :     +- *(1) Project [id#337, last_name#339]\n",
      "   :        +- *(1) Filter (last_name#339 = Tarantino)\n",
      "   :           +- Scan ExistingRDD[id#337,first_name#338,last_name#339]\n",
      "   +- *(4) Sort [director_id#343 ASC NULLS FIRST], false, 0\n",
      "      +- Exchange hashpartitioning(director_id#343, 200)\n",
      "         +- *(3) Project [director_id#343, prob#345]\n",
      "            +- *(3) Filter (genre#344 = Mystery)\n",
      "               +- Scan ExistingRDD[director_id#343,genre#344,prob#345]\n"
     ]
    }
   ],
   "source": [
    "phys_root.evaluate().explain(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SQL in Spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is also possible to pass entire SQL queries to Spark. To use a DataFrame in a query, it must be named with createOrReplaceTempView(). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----+\n",
      "|last_name| prob|\n",
      "+---------+-----+\n",
      "|Tarantino|0.125|\n",
      "+---------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "directors.df.createOrReplaceTempView(\"directors\")\n",
    "directors_genres.df.createOrReplaceTempView(\"directors_genres\")\n",
    "\n",
    "res = session.sql(\"SELECT last_name, prob \\\n",
    "                   FROM directors, directors_genres \\\n",
    "                   WHERE id == director_id and last_name == 'Tarantino' and genre == 'Mystery'\")\n",
    "res.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance in Spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SparkUI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Under <a href=\"http://localhost:4040/\">http://localhost:4040/</a> the SparkUI shows execution details of the job. \n",
    "\n",
    "1. For the previous query, a job is created. \n",
    "2. This job is split into three stages.\n",
    "   The first stage builds the \"directors\" data source and applies the selection last_name == 'Tarantino'.\n",
    "   In parallel, the second stage builds the \"directors_genres\" data source and applies the selection genre == 'Mystery'.\n",
    "   The third stage pulls the results of the two previous stages and performs the join.\n",
    "3. The operators within a stage are processed in parallel on horizontally partitioned data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The following material was not covered/shown in the lecture:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query Execution Time: Naive vs Parquet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Spark, the execution time of a query largely depends on the underlying data source. So far, the Spark DataFrames were internally wrapping Spark RDDs, which are the most fundamental data source in Spark. They simply return the entire dataset row by row. \n",
    "\n",
    "Let us see what this means for the performance. The following query joins three tables and performs two selections. We measure the runtime using %%time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "actors.df.createOrReplaceTempView(\"actors\")\n",
    "movies.df.createOrReplaceTempView(\"movies\")\n",
    "roles.df.createOrReplaceTempView(\"roles\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+---------+--------------------+\n",
      "|       first_name|last_name|                role|\n",
      "+-----------------+---------+--------------------+\n",
      "|       Jorge (II)|    Silva|      Bartender/Pimp|\n",
      "|            Clark|Middleton|               Ernie|\n",
      "|      Michael (I)|    Parks|      Esteban Vihaio|\n",
      "|        Samuel L.|  Jackson|               Rufus|\n",
      "|              Sid|     Haig|                 Jay|\n",
      "|               Bo|  Svenson|    Reverend Harmony|\n",
      "|        Al Manuel|  Douglas|     Marty Kitrosser|\n",
      "|         Chia Hui|      Liu|             Pai Mei|\n",
      "|            Stevo|    Polyi|                 Tim|\n",
      "|            Larry|   Bishop|         Larry Gomez|\n",
      "|      Michael (I)|   Madsen|   Budd (Sidewinder)|\n",
      "|            David|Carradine|Bill AKA Snake Ch...|\n",
      "|Christopher Allen|   Nelson|      Tommy Plympton|\n",
      "|     William Paul|    Clark|           Soda Jerk|\n",
      "|        James (I)|  Cameron|             Himself|\n",
      "|      Justin (II)|    Baker|        Harold Bride|\n",
      "|             Eric|  Schmitz|             Himself|\n",
      "|           Victor| Nischeta|             Himself|\n",
      "|         Don (II)|    Lynch|      Thomas Andrews|\n",
      "|              Ken|Marschall|      J. Bruce Ismay|\n",
      "+-----------------+---------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "CPU times: user 28.6 ms, sys: 0 ns, total: 28.6 ms\n",
      "Wall time: 2.04 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# query\n",
    "res = session.sql(\"SELECT first_name, last_name, role \\\n",
    "                   FROM actors, roles, movies \\\n",
    "                   WHERE actors.id == roles.actor_id \\\n",
    "                     AND roles.movie_id == movies.id \\\n",
    "                     AND gender == 'M' \\\n",
    "                     AND year >= 1995\")\n",
    "res.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following explain shows, that on the leaf level, a \"Scan ExistingRDD\" is performed, which simply returns all rows. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Physical Plan ==\n",
      "*(8) Project [first_name#5, last_name#6, role#38]\n",
      "+- *(8) SortMergeJoin [movie_id#37], [id#28], Inner\n",
      "   :- *(5) Sort [movie_id#37 ASC NULLS FIRST], false, 0\n",
      "   :  +- Exchange hashpartitioning(movie_id#37, 200)\n",
      "   :     +- *(4) Project [first_name#5, last_name#6, movie_id#37, role#38]\n",
      "   :        +- *(4) SortMergeJoin [id#4], [actor_id#36], Inner\n",
      "   :           :- *(2) Sort [id#4 ASC NULLS FIRST], false, 0\n",
      "   :           :  +- Exchange hashpartitioning(id#4, 200)\n",
      "   :           :     +- *(1) Project [id#4, first_name#5, last_name#6]\n",
      "   :           :        +- *(1) Filter (gender#7 = M)\n",
      "   :           :           +- Scan ExistingRDD[id#4,first_name#5,last_name#6,gender#7]\n",
      "   :           +- *(3) Sort [actor_id#36 ASC NULLS FIRST], false, 0\n",
      "   :              +- Exchange hashpartitioning(actor_id#36, 200)\n",
      "   :                 +- Scan ExistingRDD[actor_id#36,movie_id#37,role#38]\n",
      "   +- *(7) Sort [id#28 ASC NULLS FIRST], false, 0\n",
      "      +- Exchange hashpartitioning(id#28, 200)\n",
      "         +- *(6) Project [id#28]\n",
      "            +- *(6) Filter (year#30 >= 1995)\n",
      "               +- Scan ExistingRDD[id#28,name#29,year#30,rank#31]\n"
     ]
    }
   ],
   "source": [
    "res.explain()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To generate a more efficient physical plan, the Parquet (<a href=\"https://parquet.apache.org/\">https://parquet.apache.org/</a>) data source can be used. Due to its internal organization, Parquet enables the following optimizations:\n",
    "1. Column Projection: Only the columns, that are actually required by the query, are read and returned to the operator above.\n",
    "2. Partition Pruning: The data can be partitioned horizontally. As a consequence, only those partitions, which are actually required by the query, are read and returned to the operator above. \n",
    "3. Selection Pushdown: Parquet builds statistics on its data, such as min and max value per chunk of data. These statistics can be used to prune chunks of data, which can not contain qualifying entries. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write Parquet files (which are actually directories) from our existing DataFrames\n",
    "\n",
    "# Partition actors by gender. This rules out half the partitions for queries selecting on gender\n",
    "actors.df.write.mode(\"overwrite\").partitionBy(\"gender\").parquet(\"data/parquet/actors.parquet\")\n",
    "\n",
    "# No partitioning\n",
    "movies.df.write.mode(\"overwrite\").parquet(\"data/parquet/movies.parquet\")\n",
    "\n",
    "# No partitioning\n",
    "roles.df.write.mode(\"overwrite\").parquet(\"data/parquet/roles.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the Parquet files again and bind them to DataFrames\n",
    "actorsParquetDF = session.read.parquet(\"data/parquet/actors.parquet\")\n",
    "moviesParquetDF = session.read.parquet(\"data/parquet/movies.parquet\")\n",
    "rolesParquetDF = session.read.parquet(\"data/parquet/roles.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create temporary views to access them via spark SQL\n",
    "actorsParquetDF.createOrReplaceTempView(\"actors_parquet\")\n",
    "moviesParquetDF.createOrReplaceTempView(\"movies_parquet\")\n",
    "rolesParquetDF.createOrReplaceTempView(\"roles_parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+-----------+--------------------+\n",
      "|    first_name|  last_name|                role|\n",
      "+--------------+-----------+--------------------+\n",
      "|Dr. Anatoly M.|Sagalevitch|Anatoly Milkailavich|\n",
      "|         Vince|       Pace|             Himself|\n",
      "|  Mark Lindsay|    Chapman|Chief Officer Hen...|\n",
      "|        Hikaru| Midorikawa|Pretty Riki (anim...|\n",
      "|         Kenji|       Ohba|Bald Guy (Sushi S...|\n",
      "|         Chris|       Pare|   Rowdy college kid|\n",
      "|    Tom 'Tiny'| Lister Jr.|             Winston|\n",
      "|          Paul|      Skemp|       Real Theodore|\n",
      "|          Gary|       Mann|          The Deputy|\n",
      "|       Sakichi|       SatÃ´|       Charlie Brown|\n",
      "|          Shun|     Sugata|          Boss Benta|\n",
      "|          Paul| Brightwell|Quartermaster Rob...|\n",
      "|      Nicholas|    Cascone|         Bobby Buell|\n",
      "|       Xiaohui|         Hu|Young 88 (Spanked...|\n",
      "|         Clark|  Middleton|               Ernie|\n",
      "|       Antonio|   Banderas|Man (segment \"Mis...|\n",
      "|            Bo|    Svenson|    Reverend Harmony|\n",
      "|        Oliver|       Page|      Steward Barnes|\n",
      "|  Patrick (IV)|     Murphy|Steerage band member|\n",
      "|    James (IV)|    Garrett|      Titanic porter|\n",
      "+--------------+-----------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "CPU times: user 2.43 ms, sys: 0 ns, total: 2.43 ms\n",
      "Wall time: 651 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# query\n",
    "res = session.sql(\"SELECT first_name, last_name, role \\\n",
    "                   FROM actors_parquet, roles_parquet, movies_parquet \\\n",
    "                   WHERE actors_parquet.id == roles_parquet.actor_id \\\n",
    "                     AND roles_parquet.movie_id == movies_parquet.id \\\n",
    "                     AND gender == 'M' \\\n",
    "                     AND year >= 1995\")\n",
    "res.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The query should execute faster now, even on the small files we are using. \n",
    "\n",
    "Let us now inspect the changes in the plan. These are:\n",
    "1. The leaf is now called \"FileScan parquet\".\n",
    "2. FileScan parquet reads and returns only the columns accessed by the query, e.g. id and year of movies.\n",
    "3. FileScan parquet of actors reads and returns only one partition, namely the one containing all female actors.\n",
    "4. Filescan parquet of movies uses statistics to evaluate GreaterThanOrEqual(year,1995), such that only qualifying entries are returned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Physical Plan ==\n",
      "*(3) Project [first_name#406, last_name#407, role#423]\n",
      "+- *(3) BroadcastHashJoin [movie_id#422], [id#413], Inner, BuildRight\n",
      "   :- *(3) Project [first_name#406, last_name#407, movie_id#422, role#423]\n",
      "   :  +- *(3) BroadcastHashJoin [id#405], [actor_id#421], Inner, BuildLeft\n",
      "   :     :- BroadcastExchange HashedRelationBroadcastMode(List(cast(input[0, int, true] as bigint)))\n",
      "   :     :  +- *(1) Project [id#405, first_name#406, last_name#407]\n",
      "   :     :     +- *(1) Filter isnotnull(id#405)\n",
      "   :     :        +- *(1) FileScan parquet [id#405,first_name#406,last_name#407,gender#408] Batched: true, Format: Parquet, Location: InMemoryFileIndex[file:/home/vagrant/shared/bigdataengineering/data/parquet/actors.parquet], PartitionCount: 1, PartitionFilters: [isnotnull(gender#408), (gender#408 = M)], PushedFilters: [IsNotNull(id)], ReadSchema: struct<id:int,first_name:string,last_name:string>\n",
      "   :     +- *(3) Project [actor_id#421, movie_id#422, role#423]\n",
      "   :        +- *(3) Filter (isnotnull(actor_id#421) && isnotnull(movie_id#422))\n",
      "   :           +- *(3) FileScan parquet [actor_id#421,movie_id#422,role#423] Batched: true, Format: Parquet, Location: InMemoryFileIndex[file:/home/vagrant/shared/bigdataengineering/data/parquet/roles.parquet], PartitionFilters: [], PushedFilters: [IsNotNull(actor_id), IsNotNull(movie_id)], ReadSchema: struct<actor_id:int,movie_id:int,role:string>\n",
      "   +- BroadcastExchange HashedRelationBroadcastMode(List(cast(input[0, int, true] as bigint)))\n",
      "      +- *(2) Project [id#413]\n",
      "         +- *(2) Filter ((isnotnull(year#415) && (year#415 >= 1995)) && isnotnull(id#413))\n",
      "            +- *(2) FileScan parquet [id#413,year#415] Batched: true, Format: Parquet, Location: InMemoryFileIndex[file:/home/vagrant/shared/bigdataengineering/data/parquet/movies.parquet], PartitionFilters: [], PushedFilters: [IsNotNull(year), GreaterThanOrEqual(year,1995), IsNotNull(id)], ReadSchema: struct<id:int,year:int>\n"
     ]
    }
   ],
   "source": [
    "res.explain()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
