{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright Felix Martin Schuhknecht, Jens Dittrich & Marcel Maltry  [Big Data Analytics Group](https://bigdata.uni-saarland.de/), [CC-BY-SA](https://creativecommons.org/licenses/by-sa/4.0/legalcode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following notebook was tested with Spark 2.4.3 and requires SPARK_HOME to be set to the Spark path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from graphviz import Digraph, Source\n",
    "from ra.relation import Relation\n",
    "from ra.schema_utils import build_schema\n",
    "from os import listdir\n",
    "from ra.operators_spark import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a new Spark session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "session = SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'movies_directors': <ra.relation.Relation object at 0x11dc37fd0>, 'actors': <ra.relation.Relation object at 0x11dc33160>, 'directors': <ra.relation.Relation object at 0x11dcb72e8>, 'movies_genres': <ra.relation.Relation object at 0x11dcb7438>, 'directors_genres': <ra.relation.Relation object at 0x11dcbc6a0>, 'movies': <ra.relation.Relation object at 0x11dcbcdd8>, 'roles': <ra.relation.Relation object at 0x11dcbcd30>}\n"
     ]
    }
   ],
   "source": [
    "# Data source: https://relational.fit.cvut.cz/dataset/IMDb\n",
    "# Information courtesy of IMDb (http://www.imdb.com). Used with permission.\n",
    "# Notice: The data can only be used for personal and non-commercial use and must not\n",
    "# be altered/republished/resold/repurposed to create any kind of online/offline\n",
    "# database of movie information (except for individual personal use).\n",
    "\n",
    "path = 'data/IMDb_sample'  \n",
    "# create a list of all files in that directory that end with \"*.csv\":\n",
    "files = [file for file in listdir(path) if file.endswith('.csv')]\n",
    "\n",
    "from ra.csv_utils import load_csv\n",
    "\n",
    "relations = [load_csv(path + '/' + file, file[:-4], delimiter='\\t') for file in files]\n",
    "\n",
    "relationsDict = {}\n",
    "for rel in relations:\n",
    "    relationsDict[rel.name] = rel\n",
    "print(relationsDict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We build LeafSpark objects from existing relations. Each LeafSpark object contains the data in form of a Spark DataFrame. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build LeafRelation object from relations dictionary\n",
    "movies_directors = LeafSpark(relationsDict['movies_directors'], session)\n",
    "actors = LeafSpark(relationsDict['actors'], session)\n",
    "directors = LeafSpark(relationsDict['directors'], session)\n",
    "movies_genres = LeafSpark(relationsDict['movies_genres'], session)\n",
    "directors_genres = LeafSpark(relationsDict['directors_genres'], session)\n",
    "movies = LeafSpark(relationsDict['movies'], session)\n",
    "roles = LeafSpark(relationsDict['roles'], session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----------+---------+\n",
      "|   id|first_name|last_name|\n",
      "+-----+----------+---------+\n",
      "|11652| James (I)|  Cameron|\n",
      "|78273|   Quentin|Tarantino|\n",
      "|43095|   Stanley|  Kubrick|\n",
      "+-----+----------+---------+\n",
      "\n",
      "root\n",
      " |-- id: integer (nullable = false)\n",
      " |-- first_name: string (nullable = false)\n",
      " |-- last_name: string (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "directors.evaluate().show()\n",
    "directors.evaluate().printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "newmovies = Selection_Spark(movies, 'year>2000')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------------+----+----+\n",
      "|    id|                name|year|rank|\n",
      "+------+--------------------+----+----+\n",
      "| 10934|  Aliens of the Deep|2005| 6.5|\n",
      "|105938|Expedition: Bismarck|2002| 7.5|\n",
      "|159665| Inglorious Bastards|2006| 8.3|\n",
      "| 96779|        Earthship.TV|2001| 5.6|\n",
      "|393538|  Jimmy Kimmel Live!|2003| 6.7|\n",
      "|127297| Ghosts of the Abyss|2003| 6.7|\n",
      "|176711|   Kill Bill: Vol. 1|2003| 8.4|\n",
      "|176712|   Kill Bill: Vol. 2|2004| 8.2|\n",
      "+------+--------------------+----+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "newmovies.evaluate().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp2 = Projection_Spark(newmovies, ['id', 'year'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----+\n",
      "|    id|year|\n",
      "+------+----+\n",
      "| 10934|2005|\n",
      "|105938|2002|\n",
      "|159665|2006|\n",
      "| 96779|2001|\n",
      "|393538|2003|\n",
      "|127297|2003|\n",
      "|176711|2003|\n",
      "|176712|2004|\n",
      "+------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "exp2.evaluate().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cartesian Product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "cartesianProduct = Cartesian_Product_Spark(directors, directors_genres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----------+---------+\n",
      "|   id|first_name|last_name|\n",
      "+-----+----------+---------+\n",
      "|11652| James (I)|  Cameron|\n",
      "|78273|   Quentin|Tarantino|\n",
      "|43095|   Stanley|  Kubrick|\n",
      "+-----+----------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "directors.evaluate().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----------+---------+\n",
      "|director_id|      genre|     prob|\n",
      "+-----------+-----------+---------+\n",
      "|      11652|     Horror| 0.166667|\n",
      "|      78273|     Action|      0.5|\n",
      "|      11652|   Thriller| 0.416667|\n",
      "|      11652|Documentary|     0.25|\n",
      "|      78273|      Crime|      0.5|\n",
      "|      43095|     Action|   0.0625|\n",
      "|      11652|      Drama|     0.25|\n",
      "|      78273|    Romance|    0.125|\n",
      "|      43095|      Music|   0.0625|\n",
      "|      43095|    Mystery|   0.0625|\n",
      "|      78273|     Comedy|     0.25|\n",
      "|      78273|      Drama|     0.75|\n",
      "|      43095|     Horror|   0.0625|\n",
      "|      43095|        War|    0.375|\n",
      "|      78273|   Thriller|      0.5|\n",
      "|      11652|     Sci-Fi|      0.5|\n",
      "|      43095|      Crime|   0.1875|\n",
      "|      78273|        War|    0.125|\n",
      "|      11652|    Fantasy|0.0833333|\n",
      "|      43095|     Sci-Fi|   0.1875|\n",
      "+-----------+-----------+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "directors_genres.evaluate().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----------+---------+-----------+-----------+--------+\n",
      "|   id|first_name|last_name|director_id|      genre|    prob|\n",
      "+-----+----------+---------+-----------+-----------+--------+\n",
      "|11652| James (I)|  Cameron|      11652|     Horror|0.166667|\n",
      "|11652| James (I)|  Cameron|      78273|     Action|     0.5|\n",
      "|11652| James (I)|  Cameron|      11652|   Thriller|0.416667|\n",
      "|11652| James (I)|  Cameron|      11652|Documentary|    0.25|\n",
      "|11652| James (I)|  Cameron|      78273|      Crime|     0.5|\n",
      "|11652| James (I)|  Cameron|      43095|     Action|  0.0625|\n",
      "|11652| James (I)|  Cameron|      11652|      Drama|    0.25|\n",
      "|11652| James (I)|  Cameron|      78273|    Romance|   0.125|\n",
      "|11652| James (I)|  Cameron|      43095|      Music|  0.0625|\n",
      "|11652| James (I)|  Cameron|      43095|    Mystery|  0.0625|\n",
      "+-----+----------+---------+-----------+-----------+--------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cartesianProduct.evaluate().show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intersection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "goodmovies = Selection_Spark(movies, \"rank>=7.5\")\n",
    "goodAndNew = Intersection_Spark(newmovies, goodmovies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------------+----+----+\n",
      "|    id|                name|year|rank|\n",
      "+------+--------------------+----+----+\n",
      "|176711|   Kill Bill: Vol. 1|2003| 8.4|\n",
      "|105938|Expedition: Bismarck|2002| 7.5|\n",
      "|159665| Inglorious Bastards|2006| 8.3|\n",
      "|176712|   Kill Bill: Vol. 2|2004| 8.2|\n",
      "+------+--------------------+----+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "goodAndNew.evaluate().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, without intersection but with two conditions in the selection instead:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "goodAndNewSel = Selection_Spark(movies, \"year>2000 and rank>=7.5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------------+----+----+\n",
      "|    id|                name|year|rank|\n",
      "+------+--------------------+----+----+\n",
      "|105938|Expedition: Bismarck|2002| 7.5|\n",
      "|159665| Inglorious Bastards|2006| 8.3|\n",
      "|176711|   Kill Bill: Vol. 1|2003| 8.4|\n",
      "|176712|   Kill Bill: Vol. 2|2004| 8.2|\n",
      "+------+--------------------+----+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "goodAndNewSel.evaluate().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Union"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "goodOrNew = Union_Spark(goodmovies, newmovies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------------+----+----+\n",
      "|    id|                name|year|rank|\n",
      "+------+--------------------+----+----+\n",
      "|310455|           Spartacus|1960| 8.0|\n",
      "|121538|   Full Metal Jacket|1987| 8.2|\n",
      "| 10920|              Aliens|1986| 8.2|\n",
      "|164572|        Jackie Brown|1997| 7.5|\n",
      "|  1711|2001: A Space Ody...|1968| 8.3|\n",
      "|105938|Expedition: Bismarck|2002| 7.5|\n",
      "|328285|     Terminator, The|1984| 7.9|\n",
      "|159665| Inglorious Bastards|2006| 8.3|\n",
      "|328277|Terminator 2: Jud...|1991| 8.1|\n",
      "|387728|                  ER|1994| 7.7|\n",
      "| 92616|Dr. Strangelove o...|1964| 8.7|\n",
      "|250612|      Paths of Glory|1957| 8.6|\n",
      "| 65764| Clockwork Orange, A|1971| 8.3|\n",
      "| 30431|        Barry Lyndon|1975| 7.9|\n",
      "|177019|        Killing, The|1956| 8.1|\n",
      "|193519|              Lolita|1962| 7.6|\n",
      "|176711|   Kill Bill: Vol. 1|2003| 8.4|\n",
      "|176712|   Kill Bill: Vol. 2|2004| 8.2|\n",
      "|267038|        Pulp Fiction|1994| 8.7|\n",
      "|276217|      Reservoir Dogs|1992| 8.3|\n",
      "+------+--------------------+----+----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "goodOrNew.evaluate().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, without union but with two conditions in the selection instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "goodOrNewSel = Selection_Spark(movies, \"year>2000 or rank>=7.5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------------+----+----+\n",
      "|    id|                name|year|rank|\n",
      "+------+--------------------+----+----+\n",
      "|310455|           Spartacus|1960| 8.0|\n",
      "| 10934|  Aliens of the Deep|2005| 6.5|\n",
      "|121538|   Full Metal Jacket|1987| 8.2|\n",
      "| 10920|              Aliens|1986| 8.2|\n",
      "|164572|        Jackie Brown|1997| 7.5|\n",
      "|  1711|2001: A Space Ody...|1968| 8.3|\n",
      "|105938|Expedition: Bismarck|2002| 7.5|\n",
      "|328285|     Terminator, The|1984| 7.9|\n",
      "|159665| Inglorious Bastards|2006| 8.3|\n",
      "|328277|Terminator 2: Jud...|1991| 8.1|\n",
      "|387728|                  ER|1994| 7.7|\n",
      "| 92616|Dr. Strangelove o...|1964| 8.7|\n",
      "|250612|      Paths of Glory|1957| 8.6|\n",
      "| 65764| Clockwork Orange, A|1971| 8.3|\n",
      "| 30431|        Barry Lyndon|1975| 7.9|\n",
      "| 96779|        Earthship.TV|2001| 5.6|\n",
      "|177019|        Killing, The|1956| 8.1|\n",
      "|193519|              Lolita|1962| 7.6|\n",
      "|393538|  Jimmy Kimmel Live!|2003| 6.7|\n",
      "|127297| Ghosts of the Abyss|2003| 6.7|\n",
      "+------+--------------------+----+----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "goodOrNewSel.evaluate().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "newButBadMovies = Difference_Spark(newmovies, goodmovies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------------------+----+----+\n",
      "|    id|               name|year|rank|\n",
      "+------+-------------------+----+----+\n",
      "|393538| Jimmy Kimmel Live!|2003| 6.7|\n",
      "|127297|Ghosts of the Abyss|2003| 6.7|\n",
      "| 10934| Aliens of the Deep|2005| 6.5|\n",
      "| 96779|       Earthship.TV|2001| 5.6|\n",
      "+------+-------------------+----+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "newButBadMovies.evaluate().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, without intersection but with two conditions in the selection instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "newButBadMoviesSel = Selection_Spark(movies, \"year>2000 and not rank>=7.5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------------------+----+----+\n",
      "|    id|               name|year|rank|\n",
      "+------+-------------------+----+----+\n",
      "| 10934| Aliens of the Deep|2005| 6.5|\n",
      "| 96779|       Earthship.TV|2001| 5.6|\n",
      "|393538| Jimmy Kimmel Live!|2003| 6.7|\n",
      "|127297|Ghosts of the Abyss|2003| 6.7|\n",
      "+------+-------------------+----+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "newButBadMoviesSel.evaluate().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Renaming Relation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataFrames do not have a name. Thus, renaming has no effect\n",
    "exp11 = Renaming_Relation_Spark(goodOrNew, \"good_or_new\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------------+----+----+\n",
      "|    id|                name|year|rank|\n",
      "+------+--------------------+----+----+\n",
      "|310455|           Spartacus|1960| 8.0|\n",
      "|121538|   Full Metal Jacket|1987| 8.2|\n",
      "| 10920|              Aliens|1986| 8.2|\n",
      "|164572|        Jackie Brown|1997| 7.5|\n",
      "|  1711|2001: A Space Ody...|1968| 8.3|\n",
      "|105938|Expedition: Bismarck|2002| 7.5|\n",
      "|328285|     Terminator, The|1984| 7.9|\n",
      "|159665| Inglorious Bastards|2006| 8.3|\n",
      "|328277|Terminator 2: Jud...|1991| 8.1|\n",
      "|387728|                  ER|1994| 7.7|\n",
      "| 92616|Dr. Strangelove o...|1964| 8.7|\n",
      "|250612|      Paths of Glory|1957| 8.6|\n",
      "| 65764| Clockwork Orange, A|1971| 8.3|\n",
      "| 30431|        Barry Lyndon|1975| 7.9|\n",
      "|177019|        Killing, The|1956| 8.1|\n",
      "|193519|              Lolita|1962| 7.6|\n",
      "|176711|   Kill Bill: Vol. 1|2003| 8.4|\n",
      "|176712|   Kill Bill: Vol. 2|2004| 8.2|\n",
      "|267038|        Pulp Fiction|1994| 8.7|\n",
      "|276217|      Reservoir Dogs|1992| 8.3|\n",
      "+------+--------------------+----+----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "exp11.evaluate().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Renaming Attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp12 = Renaming_Attributes_Spark(exp11, [\"movies<-name\",\"published<-year\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------+\n",
      "|              movies|published|\n",
      "+--------------------+---------+\n",
      "|           Spartacus|     1960|\n",
      "|   Full Metal Jacket|     1987|\n",
      "|              Aliens|     1986|\n",
      "|        Jackie Brown|     1997|\n",
      "|2001: A Space Ody...|     1968|\n",
      "|Expedition: Bismarck|     2002|\n",
      "|     Terminator, The|     1984|\n",
      "| Inglorious Bastards|     2006|\n",
      "|Terminator 2: Jud...|     1991|\n",
      "|                  ER|     1994|\n",
      "|Dr. Strangelove o...|     1964|\n",
      "|      Paths of Glory|     1957|\n",
      "| Clockwork Orange, A|     1971|\n",
      "|        Barry Lyndon|     1975|\n",
      "|        Killing, The|     1956|\n",
      "|              Lolita|     1962|\n",
      "|   Kill Bill: Vol. 1|     2003|\n",
      "|   Kill Bill: Vol. 2|     2004|\n",
      "|        Pulp Fiction|     1994|\n",
      "|      Reservoir Dogs|     1992|\n",
      "+--------------------+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "exp12.evaluate().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Theta Join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "directorsAndTheirMovies = Theta_Join_Spark(directors, movies_directors, \"id==director_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----------+---------+-----------+--------+\n",
      "|   id|first_name|last_name|director_id|movie_id|\n",
      "+-----+----------+---------+-----------+--------+\n",
      "|43095|   Stanley|  Kubrick|      43095|   30431|\n",
      "|43095|   Stanley|  Kubrick|      43095|   92616|\n",
      "|43095|   Stanley|  Kubrick|      43095|    1711|\n",
      "|43095|   Stanley|  Kubrick|      43095|  176891|\n",
      "|43095|   Stanley|  Kubrick|      43095|  110246|\n",
      "|43095|   Stanley|  Kubrick|      43095|  177019|\n",
      "|43095|   Stanley|  Kubrick|      43095|   65764|\n",
      "|43095|   Stanley|  Kubrick|      43095|  106666|\n",
      "|43095|   Stanley|  Kubrick|      43095|  121538|\n",
      "|43095|   Stanley|  Kubrick|      43095|  310455|\n",
      "+-----+----------+---------+-----------+--------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "directorsAndTheirMovies.evaluate().show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Equi Join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "directorsAndTheirMovies = Equi_Join_Spark(directors, movies_directors, ['id'], ['director_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----------+---------+-----------+--------+\n",
      "|   id|first_name|last_name|director_id|movie_id|\n",
      "+-----+----------+---------+-----------+--------+\n",
      "|43095|   Stanley|  Kubrick|      43095|   30431|\n",
      "|43095|   Stanley|  Kubrick|      43095|   92616|\n",
      "|43095|   Stanley|  Kubrick|      43095|    1711|\n",
      "|43095|   Stanley|  Kubrick|      43095|  176891|\n",
      "|43095|   Stanley|  Kubrick|      43095|  110246|\n",
      "|43095|   Stanley|  Kubrick|      43095|  177019|\n",
      "|43095|   Stanley|  Kubrick|      43095|   65764|\n",
      "|43095|   Stanley|  Kubrick|      43095|  106666|\n",
      "|43095|   Stanley|  Kubrick|      43095|  121538|\n",
      "|43095|   Stanley|  Kubrick|      43095|  310455|\n",
      "+-----+----------+---------+-----------+--------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "directorsAndTheirMovies.evaluate().show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grouping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Idea: count the number of female/male actors\n",
    "\n",
    "# grouping key: ['gender']\n",
    "# aggregation function: len (also called count)\n",
    "# notice that for len() specifying an attribute is actually not required\n",
    "# as only the number of tuples in each group are coiunted\n",
    "# this is independent of a specific attribute value\n",
    "grouping = Grouping_Spark(actors, ['gender'], [(len, 'id')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---------+\n",
      "|gender|count(id)|\n",
      "+------+---------+\n",
      "|     F|      289|\n",
      "|     M|      802|\n",
      "+------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "grouping.evaluate().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Idea: count the number of movies per year\n",
    "# also sum up the years in each group which\n",
    "# does not make sense semantically, just done to\n",
    "# show that one can use multiple aggregations in a Grouping\n",
    "\n",
    "# grouping key: ['year']\n",
    "# aggregation function: len (also called count)\n",
    "# aggregation function: sum (also called count)\n",
    "grouping = Grouping_Spark(movies, ['year'], [(len, 'year'), (sum, 'id')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----------+-------+\n",
      "|year|count(year)|sum(id)|\n",
      "+----+-----------+-------+\n",
      "|1975|          1|  30431|\n",
      "|2003|          3| 697546|\n",
      "|1955|          1| 176891|\n",
      "|2006|          1| 159665|\n",
      "|1978|          1| 369522|\n",
      "|1956|          1| 177019|\n",
      "|1997|          2| 498428|\n",
      "|1994|          3| 995565|\n",
      "|1968|          1|   1711|\n",
      "|1951|          2| 196085|\n",
      "|1971|          1|  65764|\n",
      "|2004|          1| 176712|\n",
      "|1991|          1| 328277|\n",
      "|1957|          1| 250612|\n",
      "|1989|          1|   5306|\n",
      "|1996|          1| 322652|\n",
      "|1960|          1| 310455|\n",
      "|1987|          2| 345248|\n",
      "|1995|          1| 118367|\n",
      "|1980|          1| 299073|\n",
      "+----+-----------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "grouping.evaluate().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query Optimization in Spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spark SQL implements its own query optimizer. It performs the following steps:\n",
    "1. Parse the query and generate the logical plan.\n",
    "2. Analyze the logical plan. In this step, the schema is checked and types are resolved.\n",
    "3. Optimize the logical plan using rule-based optimization, e.g. by applying selection push-down\n",
    "4. Generate multiple possible physical plans and pick the cheapest one with respect to a cost-model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# spark plan \n",
    "cp = Cartesian_Product_Spark(directors, directors_genres)\n",
    "sel1 = Selection_Spark(cp, \"id == director_id\")\n",
    "sel2 = Selection_Spark(sel1, \"last_name == 'Tarantino' and genre == 'Mystery'\")\n",
    "proj = Projection_Spark(sel2, ['last_name', 'prob'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Parsed Logical Plan ==\n",
      "'Project [unresolvedalias('last_name, None), unresolvedalias('prob, None)]\n",
      "+- Filter ((last_name#14 = Tarantino) && (genre#23 = Mystery))\n",
      "   +- Filter (id#12 = director_id#22)\n",
      "      +- Join Cross\n",
      "         :- LogicalRDD [id#12, first_name#13, last_name#14], false\n",
      "         +- LogicalRDD [director_id#22, genre#23, prob#24], false\n",
      "\n",
      "== Analyzed Logical Plan ==\n",
      "last_name: string, prob: float\n",
      "Project [last_name#14, prob#24]\n",
      "+- Filter ((last_name#14 = Tarantino) && (genre#23 = Mystery))\n",
      "   +- Filter (id#12 = director_id#22)\n",
      "      +- Join Cross\n",
      "         :- LogicalRDD [id#12, first_name#13, last_name#14], false\n",
      "         +- LogicalRDD [director_id#22, genre#23, prob#24], false\n",
      "\n",
      "== Optimized Logical Plan ==\n",
      "Project [last_name#14, prob#24]\n",
      "+- Join Cross, (id#12 = director_id#22)\n",
      "   :- Project [id#12, last_name#14]\n",
      "   :  +- Filter (last_name#14 = Tarantino)\n",
      "   :     +- LogicalRDD [id#12, first_name#13, last_name#14], false\n",
      "   +- Project [director_id#22, prob#24]\n",
      "      +- Filter (genre#23 = Mystery)\n",
      "         +- LogicalRDD [director_id#22, genre#23, prob#24], false\n",
      "\n",
      "== Physical Plan ==\n",
      "*(5) Project [last_name#14, prob#24]\n",
      "+- *(5) SortMergeJoin [id#12], [director_id#22], Cross\n",
      "   :- *(2) Sort [id#12 ASC NULLS FIRST], false, 0\n",
      "   :  +- Exchange hashpartitioning(id#12, 200)\n",
      "   :     +- *(1) Project [id#12, last_name#14]\n",
      "   :        +- *(1) Filter (last_name#14 = Tarantino)\n",
      "   :           +- Scan ExistingRDD[id#12,first_name#13,last_name#14]\n",
      "   +- *(4) Sort [director_id#22 ASC NULLS FIRST], false, 0\n",
      "      +- Exchange hashpartitioning(director_id#22, 200)\n",
      "         +- *(3) Project [director_id#22, prob#24]\n",
      "            +- *(3) Filter (genre#23 = Mystery)\n",
      "               +- Scan ExistingRDD[director_id#22,genre#23,prob#24]\n"
     ]
    }
   ],
   "source": [
    "# print logical and physical plan\n",
    "proj.evaluate().explain(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logical to Spark Plan Compilation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----+\n",
      "|last_name| prob|\n",
      "+---------+-----+\n",
      "|Tarantino|0.125|\n",
      "+---------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# one to one translation from our logical operators to our spark operators.\n",
    "def logical_to_spark(op):\n",
    "    if(isinstance(op, LeafOperator)): return LeafSpark(op.relation, session)\n",
    "    elif(isinstance(op, Selection)): return Selection_Spark(op.input, op.predicate)\n",
    "    elif(isinstance(op, Projection)): return Projection_Spark(op.input, op.attributes)\n",
    "    elif(isinstance(op, Cartesian_Product)): return Cartesian_Product_Spark(op.l_input, op.r_input) \n",
    "    elif(isinstance(op, SetOperator)): return SetOperator_Spark(op.l_input, op.r_input, op.operator, op.symbol)\n",
    "    elif(isinstance(op, Renaming_Relation)): return Renaming_Relation_Spark(op.input, op.name)\n",
    "    elif(isinstance(op, Renaming_Attributes)): return Renaming_Attributes_Spark(op.input, op.changes) \n",
    "    elif(isinstance(op, Theta_Join)): return Theta_Join_Spark(op.l_input, op.r_input, op.theta) \n",
    "    elif(isinstance(op, Equi_Join)): return Equi_Join_Spark(op.l_input, op.r_input, op.l_attrs, op.r_attrs)\n",
    "    elif(isinstance(op, Grouping)): return Grouping_Spark(op.input, op.group_by, op.aggregations)    \n",
    "    else: return None\n",
    "\n",
    "# compile a logical operator tree to a spark operator tree\n",
    "def compile_to_spark(op):\n",
    "    new_op = logical_to_spark(op)\n",
    "    if(isinstance(op, UnaryOperator)):\n",
    "        new_op.input = compile_to_spark(op.input)\n",
    "    elif(isinstance(op, BinaryOperator)):\n",
    "        new_op.l_input = compile_to_spark(op.l_input)\n",
    "        new_op.r_input = compile_to_spark(op.r_input)\n",
    "    return new_op\n",
    "\n",
    "# logical plan\n",
    "cp = Cartesian_Product(directors, directors_genres)\n",
    "sel1 = Selection(cp, \"id == director_id\")\n",
    "sel2 = Selection(sel1, \"last_name == 'Tarantino' and genre == 'Mystery'\")\n",
    "proj = Projection(sel2, ['last_name', 'prob'])\n",
    "\n",
    "# compile\n",
    "phys_root = compile_to_spark(proj)\n",
    "\n",
    "# run \n",
    "phys_root.evaluate().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Parsed Logical Plan ==\n",
      "'Project [unresolvedalias('last_name, None), unresolvedalias('prob, None)]\n",
      "+- Filter ((last_name#374 = Tarantino) && (genre#379 = Mystery))\n",
      "   +- Filter (id#372 = director_id#378)\n",
      "      +- Join Cross\n",
      "         :- LogicalRDD [id#372, first_name#373, last_name#374], false\n",
      "         +- LogicalRDD [director_id#378, genre#379, prob#380], false\n",
      "\n",
      "== Analyzed Logical Plan ==\n",
      "last_name: string, prob: float\n",
      "Project [last_name#374, prob#380]\n",
      "+- Filter ((last_name#374 = Tarantino) && (genre#379 = Mystery))\n",
      "   +- Filter (id#372 = director_id#378)\n",
      "      +- Join Cross\n",
      "         :- LogicalRDD [id#372, first_name#373, last_name#374], false\n",
      "         +- LogicalRDD [director_id#378, genre#379, prob#380], false\n",
      "\n",
      "== Optimized Logical Plan ==\n",
      "Project [last_name#374, prob#380]\n",
      "+- Join Cross, (id#372 = director_id#378)\n",
      "   :- Project [id#372, last_name#374]\n",
      "   :  +- Filter (last_name#374 = Tarantino)\n",
      "   :     +- LogicalRDD [id#372, first_name#373, last_name#374], false\n",
      "   +- Project [director_id#378, prob#380]\n",
      "      +- Filter (genre#379 = Mystery)\n",
      "         +- LogicalRDD [director_id#378, genre#379, prob#380], false\n",
      "\n",
      "== Physical Plan ==\n",
      "*(5) Project [last_name#374, prob#380]\n",
      "+- *(5) SortMergeJoin [id#372], [director_id#378], Cross\n",
      "   :- *(2) Sort [id#372 ASC NULLS FIRST], false, 0\n",
      "   :  +- Exchange hashpartitioning(id#372, 200)\n",
      "   :     +- *(1) Project [id#372, last_name#374]\n",
      "   :        +- *(1) Filter (last_name#374 = Tarantino)\n",
      "   :           +- Scan ExistingRDD[id#372,first_name#373,last_name#374]\n",
      "   +- *(4) Sort [director_id#378 ASC NULLS FIRST], false, 0\n",
      "      +- Exchange hashpartitioning(director_id#378, 200)\n",
      "         +- *(3) Project [director_id#378, prob#380]\n",
      "            +- *(3) Filter (genre#379 = Mystery)\n",
      "               +- Scan ExistingRDD[director_id#378,genre#379,prob#380]\n"
     ]
    }
   ],
   "source": [
    "phys_root.evaluate().explain(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SQL in Spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is also possible to pass entire SQL queries to Spark. To use a DataFrame in a query, it must be named with createOrReplaceTempView(). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----+\n",
      "|last_name| prob|\n",
      "+---------+-----+\n",
      "|Tarantino|0.125|\n",
      "+---------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "directors.df.createOrReplaceTempView(\"directors\")\n",
    "directors_genres.df.createOrReplaceTempView(\"directors_genres\")\n",
    "\n",
    "res = session.sql(\"SELECT last_name, prob \\\n",
    "                   FROM directors, directors_genres \\\n",
    "                   WHERE id == director_id and last_name == 'Tarantino' and genre == 'Mystery'\")\n",
    "res.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance in Spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SparkUI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Under <a href=\"http://localhost:4040/\">http://localhost:4040/</a> the SparkUI shows execution details of the job. \n",
    "\n",
    "1. For the previous query, a job is created. \n",
    "2. This job is split into three stages.\n",
    "   The first stage builds the \"directors\" data source and applies the selection last_name == 'Tarantino'.\n",
    "   In parallel, the second stage builds the \"directors_genres\" data source and applies the selection genre == 'Mystery'.\n",
    "   The third stage pulls the results of the two previous stages and performs the join.\n",
    "3. The operators within a stage are processed in parallel on horizontally partitioned data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The following material was not covered/shown in the lecture:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query Execution Time: Naive vs Parquet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Spark, the execution time of a query largely depends on the underlying data source. So far, the Spark DataFrames were internally wrapping Spark RDDs, which are the most fundamental data source in Spark. They simply return the entire dataset row by row. \n",
    "\n",
    "Let us see what this means for the performance. The following query joins three tables and performs two selections. We measure the runtime using %%time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "actors.df.createOrReplaceTempView(\"actors\")\n",
    "movies.df.createOrReplaceTempView(\"movies\")\n",
    "roles.df.createOrReplaceTempView(\"roles\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+---------+--------------------+\n",
      "|       first_name|last_name|                role|\n",
      "+-----------------+---------+--------------------+\n",
      "|       Jorge (II)|    Silva|      Bartender/Pimp|\n",
      "|            Clark|Middleton|               Ernie|\n",
      "|      Michael (I)|    Parks|      Esteban Vihaio|\n",
      "|        Samuel L.|  Jackson|               Rufus|\n",
      "|              Sid|     Haig|                 Jay|\n",
      "|               Bo|  Svenson|    Reverend Harmony|\n",
      "|        Al Manuel|  Douglas|     Marty Kitrosser|\n",
      "|         Chia Hui|      Liu|             Pai Mei|\n",
      "|            Stevo|    Polyi|                 Tim|\n",
      "|            Larry|   Bishop|         Larry Gomez|\n",
      "|      Michael (I)|   Madsen|   Budd (Sidewinder)|\n",
      "|            David|Carradine|Bill AKA Snake Ch...|\n",
      "|Christopher Allen|   Nelson|      Tommy Plympton|\n",
      "|     William Paul|    Clark|           Soda Jerk|\n",
      "|        James (I)|  Cameron|             Himself|\n",
      "|      Justin (II)|    Baker|        Harold Bride|\n",
      "|             Eric|  Schmitz|             Himself|\n",
      "|           Victor| Nischeta|             Himself|\n",
      "|         Don (II)|    Lynch|      Thomas Andrews|\n",
      "|              Ken|Marschall|      J. Bruce Ismay|\n",
      "+-----------------+---------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "CPU times: user 24.4 ms, sys: 10.1 ms, total: 34.6 ms\n",
      "Wall time: 1.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# query\n",
    "res = session.sql(\"SELECT first_name, last_name, role \\\n",
    "                   FROM actors, roles, movies \\\n",
    "                   WHERE actors.id == roles.actor_id \\\n",
    "                     AND roles.movie_id == movies.id \\\n",
    "                     AND gender == 'M' \\\n",
    "                     AND year >= 1995\")\n",
    "res.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following explain shows, that on the leaf level, a \"Scan ExistingRDD\" is performed, which simply returns all rows. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Physical Plan ==\n",
      "*(8) Project [first_name#5, last_name#6, role#38]\n",
      "+- *(8) SortMergeJoin [movie_id#37], [id#28], Inner\n",
      "   :- *(5) Sort [movie_id#37 ASC NULLS FIRST], false, 0\n",
      "   :  +- Exchange hashpartitioning(movie_id#37, 200)\n",
      "   :     +- *(4) Project [first_name#5, last_name#6, movie_id#37, role#38]\n",
      "   :        +- *(4) SortMergeJoin [id#4], [actor_id#36], Inner\n",
      "   :           :- *(2) Sort [id#4 ASC NULLS FIRST], false, 0\n",
      "   :           :  +- Exchange hashpartitioning(id#4, 200)\n",
      "   :           :     +- *(1) Project [id#4, first_name#5, last_name#6]\n",
      "   :           :        +- *(1) Filter (gender#7 = M)\n",
      "   :           :           +- Scan ExistingRDD[id#4,first_name#5,last_name#6,gender#7]\n",
      "   :           +- *(3) Sort [actor_id#36 ASC NULLS FIRST], false, 0\n",
      "   :              +- Exchange hashpartitioning(actor_id#36, 200)\n",
      "   :                 +- Scan ExistingRDD[actor_id#36,movie_id#37,role#38]\n",
      "   +- *(7) Sort [id#28 ASC NULLS FIRST], false, 0\n",
      "      +- Exchange hashpartitioning(id#28, 200)\n",
      "         +- *(6) Project [id#28]\n",
      "            +- *(6) Filter (year#30 >= 1995)\n",
      "               +- Scan ExistingRDD[id#28,name#29,year#30,rank#31]\n"
     ]
    }
   ],
   "source": [
    "res.explain()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To generate a more efficient physical plan, the Parquet (<a href=\"https://parquet.apache.org/\">https://parquet.apache.org/</a>) data source can be used. Due to its internal organization, Parquet enables the following optimizations:\n",
    "1. Column Projection: Only the columns, that are actually required by the query, are read and returned to the operator above.\n",
    "2. Partition Pruning: The data can be partitioned horizontally. As a consequence, only those partitions, which are actually required by the query, are read and returned to the operator above. \n",
    "3. Selection Pushdown: Parquet builds statistics on its data, such as min and max value per chunk of data. These statistics can be used to prune chunks of data, which can not contain qualifying entries. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write Parquet files (which are actually directories) from our existing DataFrames\n",
    "\n",
    "# Partition actors by gender. This rules out half the partitions for queries selecting on gender\n",
    "actors.df.write.mode(\"overwrite\").partitionBy(\"gender\").parquet(\"data/parquet/actors.parquet\")\n",
    "\n",
    "# No partitioning\n",
    "movies.df.write.mode(\"overwrite\").parquet(\"data/parquet/movies.parquet\")\n",
    "\n",
    "# No partitioning\n",
    "roles.df.write.mode(\"overwrite\").parquet(\"data/parquet/roles.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the Parquet files again and bind them to DataFrames\n",
    "actorsParquetDF = session.read.parquet(\"data/parquet/actors.parquet\")\n",
    "moviesParquetDF = session.read.parquet(\"data/parquet/movies.parquet\")\n",
    "rolesParquetDF = session.read.parquet(\"data/parquet/roles.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create temporary views to access them via spark SQL\n",
    "actorsParquetDF.createOrReplaceTempView(\"actors_parquet\")\n",
    "moviesParquetDF.createOrReplaceTempView(\"movies_parquet\")\n",
    "rolesParquetDF.createOrReplaceTempView(\"roles_parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------------+--------------------+\n",
      "| first_name|     last_name|                role|\n",
      "+-----------+--------------+--------------------+\n",
      "|      Heinz|         Steeg|             Himself|\n",
      "|   Seth (I)|        Adkins|Slovakian three-y...|\n",
      "|Michael (I)|        Madsen|      Babe Buchinsky|\n",
      "|    Xiaohui|            Hu|Young 88 (Spanked...|\n",
      "|  James (I)|       Cameron|             Himself|\n",
      "|  James (I)|       Cameron|             Himself|\n",
      "|       Marc|          Cass|     Hold steward #1|\n",
      "|   Leonardo|      DiCaprio|         Jack Dawson|\n",
      "|     Victor|        Garber|      Thomas Andrews|\n",
      "|     Arnold|Schwarzenegger|      The Terminator|\n",
      "|  Chris (I)|         Byrne|   Stairwell steward|\n",
      "|      Blake|        Sutton| Young Walter Weintz|\n",
      "|    Michael|         Biehn|          Kyle Reese|\n",
      "|      Clark|     Middleton|               Ernie|\n",
      "|   Aaron C.|    Fitzgerald|          Fred Fleet|\n",
      "|       Rudy|       Joffroy|      'Safe' Bellboy|\n",
      "|   John (I)|         Bruno|             Himself|\n",
      "|      Derek|           Lea|Leading Fireman F...|\n",
      "|      Stevo|         Polyi|                 Tim|\n",
      "|    Sakichi|          Satô|       Charlie Brown|\n",
      "+-----------+--------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "CPU times: user 1.19 ms, sys: 1.52 ms, total: 2.72 ms\n",
      "Wall time: 428 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# query\n",
    "res = session.sql(\"SELECT first_name, last_name, role \\\n",
    "                   FROM actors_parquet, roles_parquet, movies_parquet \\\n",
    "                   WHERE actors_parquet.id == roles_parquet.actor_id \\\n",
    "                     AND roles_parquet.movie_id == movies_parquet.id \\\n",
    "                     AND gender == 'M' \\\n",
    "                     AND year >= 1995\")\n",
    "res.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The query should execute faster now, even on the small files we are using. \n",
    "\n",
    "Let us now inspect the changes in the plan. These are:\n",
    "1. The leaf is now called \"FileScan parquet\".\n",
    "2. FileScan parquet reads and returns only the columns accessed by the query, e.g. id and year of movies.\n",
    "3. FileScan parquet of actors reads and returns only one partition, namely the one containing all female actors.\n",
    "4. Filescan parquet of movies uses statistics to evaluate GreaterThanOrEqual(year,1995), such that only qualifying entries are returned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Physical Plan ==\n",
      "*(3) Project [first_name#441, last_name#442, role#458]\n",
      "+- *(3) BroadcastHashJoin [movie_id#457], [id#448], Inner, BuildRight\n",
      "   :- *(3) Project [first_name#441, last_name#442, movie_id#457, role#458]\n",
      "   :  +- *(3) BroadcastHashJoin [id#440], [actor_id#456], Inner, BuildLeft\n",
      "   :     :- BroadcastExchange HashedRelationBroadcastMode(List(cast(input[0, int, true] as bigint)))\n",
      "   :     :  +- *(1) Project [id#440, first_name#441, last_name#442]\n",
      "   :     :     +- *(1) Filter isnotnull(id#440)\n",
      "   :     :        +- *(1) FileScan parquet [id#440,first_name#441,last_name#442,gender#443] Batched: true, Format: Parquet, Location: InMemoryFileIndex[file:/Users/jens/Desktop/bigdataengineering.git/trunk/data/parquet/actors.parquet], PartitionCount: 1, PartitionFilters: [isnotnull(gender#443), (gender#443 = M)], PushedFilters: [IsNotNull(id)], ReadSchema: struct<id:int,first_name:string,last_name:string>\n",
      "   :     +- *(3) Project [actor_id#456, movie_id#457, role#458]\n",
      "   :        +- *(3) Filter (isnotnull(actor_id#456) && isnotnull(movie_id#457))\n",
      "   :           +- *(3) FileScan parquet [actor_id#456,movie_id#457,role#458] Batched: true, Format: Parquet, Location: InMemoryFileIndex[file:/Users/jens/Desktop/bigdataengineering.git/trunk/data/parquet/roles.parquet], PartitionFilters: [], PushedFilters: [IsNotNull(actor_id), IsNotNull(movie_id)], ReadSchema: struct<actor_id:int,movie_id:int,role:string>\n",
      "   +- BroadcastExchange HashedRelationBroadcastMode(List(cast(input[0, int, true] as bigint)))\n",
      "      +- *(2) Project [id#448]\n",
      "         +- *(2) Filter ((isnotnull(year#450) && (year#450 >= 1995)) && isnotnull(id#448))\n",
      "            +- *(2) FileScan parquet [id#448,year#450] Batched: true, Format: Parquet, Location: InMemoryFileIndex[file:/Users/jens/Desktop/bigdataengineering.git/trunk/data/parquet/movies.parquet], PartitionFilters: [], PushedFilters: [IsNotNull(year), GreaterThanOrEqual(year,1995), IsNotNull(id)], ReadSchema: struct<id:int,year:int>\n"
     ]
    }
   ],
   "source": [
    "res.explain()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
